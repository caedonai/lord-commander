# Plugins API

No description available

**Module Path**: `src/plugins`  
**Total Exports**: 70

## ðŸ“‹ Exports Overview

| Type | Count | Examples |
|------|-------|----------|
| **function** | 37 | `add`, `applyUpdate`, `checkout`, ... |
| **interface** | 26 | `BatchOperationOptions`, `ChangeDetectionOptions`, `CloneOptions`, ... |
| **type** | 2 | `PackageManager`, `WorkspaceType` |
| **constant** | 5 | `PLACEHOLDER_CONFIG_LOADER`, `PLACEHOLDER_GIT`, `PLACEHOLDER_TELEMETRY`, ... |

## ðŸ“– Detailed Documentation

## add

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function add(
  files: string | string[],
  cwd: string = process.cwd()
): Promise<void>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area

---

## applyUpdate

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export async function applyUpdate(
  plan: UpdatePlan,
  targetDir: string,
  options: UpdateOptions =
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation) / export function satisfiesRange(version: SemanticVersion, range: string): boolean { // Basic range patterns: "^1.2.3", "~1.2.3", ">=1.2.3", "1.2.3" if (range.startsWith('^')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('~')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && version.minor === targetVersion.minor && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) > 0; } if (range.startsWith('<=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) <= 0; } if (range.startsWith('<')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) < 0; } // Exact match const targetVersion = parseVersion(range); return compareVersions(version, targetVersion) === 0; } // Git-based version diffing /** Get detailed diff between two git tags/commits / export async function getVersionDiff( fromTag: string, toTag: string, cwd: string = process.cwd() ): Promise<VersionDiff> { const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); try { // Get commit history between versions const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); // Get file changes const files = await getFilesBetweenTags(fromTag, toTag, cwd); // Determine if this is a breaking change const breaking = await isBreakingChange(fromTag, toTag, cwd); return { from: fromVersion, to: toVersion, changeType: getChangeType(fromVersion, toVersion), files, commits, breaking }; } catch (error) { throw new CLIError(`Failed to get version diff from ${fromTag} to ${toTag}`, { code: 'VERSION_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { fromTag, toTag, cwd } }); } } /** Get commits between two git tags / async function getCommitsBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<git.GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await execa('git', ['log', `${fromTag}..${toTag}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message }; }); } catch (error) { throw new CLIError(`Failed to get commits between ${fromTag} and ${toTag}`, { code: 'GIT_COMMITS_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Get detailed file changes between two git tags / async function getFilesBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<FileDiff[]> { try { // Get file stats const statsResult = await execa('git', ['diff', '--numstat', `${fromTag}..${toTag}`], { cwd }); const stats = new Map<string, { insertions: number; deletions: number }>(); for (const line of statsResult.stdout.trim().split('\n').filter(Boolean)) { const [insertions, deletions, path] = line.split('\t'); stats.set(path, { insertions: insertions === '-' ? 0 : parseInt(insertions, 10), deletions: deletions === '-' ? 0 : parseInt(deletions, 10) }); } // Get file status (added, modified, deleted, renamed) const nameStatusResult = await execa('git', ['diff', '--name-status', `${fromTag}..${toTag}`], { cwd }); const files: FileDiff[] = []; for (const line of nameStatusResult.stdout.trim().split('\n').filter(Boolean)) { const parts = line.split('\t'); const status = parts[0]; const path = parts[1]; let fileStatus: FileDiff['status']; let oldPath: string | undefined; if (status === 'A') { fileStatus = 'added'; } else if (status === 'D') { fileStatus = 'deleted'; } else if (status === 'M') { fileStatus = 'modified'; } else if (status.startsWith('R')) { fileStatus = 'renamed'; oldPath = path; // For renames, the new path is in parts[2] const newPath = parts[2]; const fileStats = stats.get(newPath) || { insertions: 0, deletions: 0 }; files.push({ path: newPath, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); continue; } else { fileStatus = 'modified'; // Default for other statuses } const fileStats = stats.get(path) || { insertions: 0, deletions: 0 }; files.push({ path, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); } return files; } catch (error) { throw new CLIError(`Failed to get file changes between ${fromTag} and ${toTag}`, { code: 'GIT_FILES_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Heuristic to determine if changes are breaking / async function isBreakingChange( fromTag: string, toTag: string, cwd: string ): Promise<boolean> { try { // Check commit messages for breaking change indicators const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); const breakingKeywords = [ 'BREAKING CHANGE', 'breaking change', 'BREAKING:', '!:', 'breaking:', 'BC:', 'bc:' ]; const hasBreakingCommit = commits.some(commit => breakingKeywords.some(keyword => commit.message.toLowerCase().includes(keyword.toLowerCase()) ) ); if (hasBreakingCommit) return true; // Check for major version bump const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); return fromVersion.major !== toVersion.major; } catch { // Default to false if we can't determine return false; } } // Update planning and application /** Create an update plan for applying changes / export async function createUpdatePlan( fromVersion: string, toVersion: string, targetDir: string, options: UpdateOptions = {} ): Promise<UpdatePlan> { try { const diff = await getVersionDiff(fromVersion, toVersion, targetDir); const conflicts = await detectConflicts(diff, targetDir); const strategy: UpdateStrategy = { type: options.strategy?.type || 'merge', excludePaths: options.strategy?.excludePaths || [ '.git', 'node_modules', '.env', '.env.local' ], preserveFiles: options.strategy?.preserveFiles || [ 'package.json', 'README.md', '.gitignore' ], customMergers: options.strategy?.customMergers || {} }; return { fromVersion, toVersion, diff, conflicts, strategy, backupRequired: options.createBackup !== false || conflicts.length > 0 }; } catch (error) { throw new CLIError(`Failed to create update plan`, { code: 'UPDATE_PLAN_FAILED', cause: error instanceof Error ? error : undefined, context: { fromVersion, toVersion, targetDir } }); } } /** Detect potential conflicts in the update / async function detectConflicts( diff: VersionDiff, targetDir: string ): Promise<UpdateConflict[]> { const conflicts: UpdateConflict[] = []; for (const file of diff.files) { const filePath = path.join(targetDir, file.path); try { // Check if file exists and has local changes if (await exists(filePath)) { if (file.status === 'deleted') { conflicts.push({ file: file.path, type: 'deletion', description: `File exists locally but is deleted in the update`, resolution: 'manual' }); } else if (file.status === 'modified') { // Could check git status here to see if file has local changes const hasLocalChanges = await checkLocalChanges(filePath, targetDir); if (hasLocalChanges) { conflicts.push({ file: file.path, type: 'content', description: `File has both local and remote changes`, resolution: 'merge' }); } } } // Check file permissions const stats = await fs.stat(filePath).catch(() => null); if (stats && !stats.isFile()) { conflicts.push({ file: file.path, type: 'permission', description: `Path exists but is not a regular file`, resolution: 'skip' }); } } catch { // File doesn't exist - no conflict } } return conflicts; } /** Check if a file has local changes (not committed) / async function checkLocalChanges(filePath: string, cwd: string): Promise<boolean> { try { const relativePath = path.relative(cwd, filePath); const result = await execa('git', ['status', '--porcelain', relativePath], { cwd }); return result.stdout.trim().length > 0; } catch { return false; } } /** Apply an update plan

---

## BatchOperationOptions

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## ChangeDetectionOptions

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## checkout

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function checkout(
  ref: string,
  cwd: string = process.cwd()
): Promise<void>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit / export async function commit( options: CommitOptions, cwd: string = process.cwd() ): Promise<string> { const args = ['commit', '-m', options.message]; if (options.amend) { args.push('--amend'); } if (options.signOff) { args.push('--signoff'); } if (options.allowEmpty) { args.push('--allow-empty'); } try { const result = await gitExeca(args, { cwd }); // Extract commit hash from output const match = result.stdout.match(/\[.+ ([a-f0-9]+)\]/); return match ? match[1] : ''; } catch (error) { throw new CLIError(`Failed to create commit`, { code: 'GIT_COMMIT_FAILED', cause: error instanceof Error ? error : undefined, context: { options, cwd }, }); } } /** Get commit history / export async function getCommits( count: number = 10, cwd: string = process.cwd() ): Promise<GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await gitExeca(['log', `-${count}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message, }; }); } catch (error) { throw new CLIError(`Failed to get commits`, { code: 'GIT_LOG_FAILED', cause: error instanceof Error ? error : undefined, context: { count, cwd }, }); } } /** Get basic diff information / export async function getDiff( from?: string, to?: string, cwd: string = process.cwd() ): Promise<string> { const args = ['diff']; if (from) { args.push(from); if (to) { args.push(to); } } try { const result = await gitExeca(args, { cwd }); return result.stdout; } catch (error) { throw new CLIError(`Failed to get diff`, { code: 'GIT_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { from, to, cwd }, }); } } /** Get branches / export async function getBranches( cwd: string = process.cwd(), includeRemote: boolean = false ): Promise<string[]> { const args = ['branch']; if (includeRemote) { args.push('-a'); } try { const result = await gitExeca(args, { cwd }); return result.stdout .trim() .split('\n') .map(line => line.replace(/^\*?\s+/, '').trim()) .filter(line => line && !line.startsWith('->')); } catch (error) { throw new CLIError(`Failed to list branches`, { code: 'GIT_BRANCH_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, includeRemote }, }); } } /** Create a new branch / export async function createBranch( name: string, cwd: string = process.cwd(), checkout: boolean = false ): Promise<void> { const args = checkout ? ['checkout', '-b', name] : ['branch', name]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to create branch`, { code: 'GIT_BRANCH_CREATE_FAILED', cause: error instanceof Error ? error : undefined, context: { name, cwd, checkout }, }); } } /** Checkout a branch or commit

---

## clone

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function clone(
  url: string,
  directory: string,
  options: CloneOptions =
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository

---

## CloneOptions

**Type**: `interface`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

---

## commit

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function commit(
  options: CommitOptions,
  cwd: string = process.cwd()
): Promise<string>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit

---

## CommitOptions

**Type**: `interface`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

---

## compareVersions

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export function compareVersions(a: SemanticVersion, b: SemanticVersion): number
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b

---

## createBranch

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function createBranch(
  name: string,
  cwd: string = process.cwd(),
  checkout: boolean = false
): Promise<void>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit / export async function commit( options: CommitOptions, cwd: string = process.cwd() ): Promise<string> { const args = ['commit', '-m', options.message]; if (options.amend) { args.push('--amend'); } if (options.signOff) { args.push('--signoff'); } if (options.allowEmpty) { args.push('--allow-empty'); } try { const result = await gitExeca(args, { cwd }); // Extract commit hash from output const match = result.stdout.match(/\[.+ ([a-f0-9]+)\]/); return match ? match[1] : ''; } catch (error) { throw new CLIError(`Failed to create commit`, { code: 'GIT_COMMIT_FAILED', cause: error instanceof Error ? error : undefined, context: { options, cwd }, }); } } /** Get commit history / export async function getCommits( count: number = 10, cwd: string = process.cwd() ): Promise<GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await gitExeca(['log', `-${count}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message, }; }); } catch (error) { throw new CLIError(`Failed to get commits`, { code: 'GIT_LOG_FAILED', cause: error instanceof Error ? error : undefined, context: { count, cwd }, }); } } /** Get basic diff information / export async function getDiff( from?: string, to?: string, cwd: string = process.cwd() ): Promise<string> { const args = ['diff']; if (from) { args.push(from); if (to) { args.push(to); } } try { const result = await gitExeca(args, { cwd }); return result.stdout; } catch (error) { throw new CLIError(`Failed to get diff`, { code: 'GIT_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { from, to, cwd }, }); } } /** Get branches / export async function getBranches( cwd: string = process.cwd(), includeRemote: boolean = false ): Promise<string[]> { const args = ['branch']; if (includeRemote) { args.push('-a'); } try { const result = await gitExeca(args, { cwd }); return result.stdout .trim() .split('\n') .map(line => line.replace(/^\*?\s+/, '').trim()) .filter(line => line && !line.startsWith('->')); } catch (error) { throw new CLIError(`Failed to list branches`, { code: 'GIT_BRANCH_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, includeRemote }, }); } } /** Create a new branch

---

## createTag

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export async function createTag(
  tag: string, 
  message?: string, 
  cwd: string = process.cwd()
): Promise<void>
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation) / export function satisfiesRange(version: SemanticVersion, range: string): boolean { // Basic range patterns: "^1.2.3", "~1.2.3", ">=1.2.3", "1.2.3" if (range.startsWith('^')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('~')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && version.minor === targetVersion.minor && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) > 0; } if (range.startsWith('<=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) <= 0; } if (range.startsWith('<')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) < 0; } // Exact match const targetVersion = parseVersion(range); return compareVersions(version, targetVersion) === 0; } // Git-based version diffing /** Get detailed diff between two git tags/commits / export async function getVersionDiff( fromTag: string, toTag: string, cwd: string = process.cwd() ): Promise<VersionDiff> { const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); try { // Get commit history between versions const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); // Get file changes const files = await getFilesBetweenTags(fromTag, toTag, cwd); // Determine if this is a breaking change const breaking = await isBreakingChange(fromTag, toTag, cwd); return { from: fromVersion, to: toVersion, changeType: getChangeType(fromVersion, toVersion), files, commits, breaking }; } catch (error) { throw new CLIError(`Failed to get version diff from ${fromTag} to ${toTag}`, { code: 'VERSION_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { fromTag, toTag, cwd } }); } } /** Get commits between two git tags / async function getCommitsBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<git.GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await execa('git', ['log', `${fromTag}..${toTag}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message }; }); } catch (error) { throw new CLIError(`Failed to get commits between ${fromTag} and ${toTag}`, { code: 'GIT_COMMITS_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Get detailed file changes between two git tags / async function getFilesBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<FileDiff[]> { try { // Get file stats const statsResult = await execa('git', ['diff', '--numstat', `${fromTag}..${toTag}`], { cwd }); const stats = new Map<string, { insertions: number; deletions: number }>(); for (const line of statsResult.stdout.trim().split('\n').filter(Boolean)) { const [insertions, deletions, path] = line.split('\t'); stats.set(path, { insertions: insertions === '-' ? 0 : parseInt(insertions, 10), deletions: deletions === '-' ? 0 : parseInt(deletions, 10) }); } // Get file status (added, modified, deleted, renamed) const nameStatusResult = await execa('git', ['diff', '--name-status', `${fromTag}..${toTag}`], { cwd }); const files: FileDiff[] = []; for (const line of nameStatusResult.stdout.trim().split('\n').filter(Boolean)) { const parts = line.split('\t'); const status = parts[0]; const path = parts[1]; let fileStatus: FileDiff['status']; let oldPath: string | undefined; if (status === 'A') { fileStatus = 'added'; } else if (status === 'D') { fileStatus = 'deleted'; } else if (status === 'M') { fileStatus = 'modified'; } else if (status.startsWith('R')) { fileStatus = 'renamed'; oldPath = path; // For renames, the new path is in parts[2] const newPath = parts[2]; const fileStats = stats.get(newPath) || { insertions: 0, deletions: 0 }; files.push({ path: newPath, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); continue; } else { fileStatus = 'modified'; // Default for other statuses } const fileStats = stats.get(path) || { insertions: 0, deletions: 0 }; files.push({ path, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); } return files; } catch (error) { throw new CLIError(`Failed to get file changes between ${fromTag} and ${toTag}`, { code: 'GIT_FILES_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Heuristic to determine if changes are breaking / async function isBreakingChange( fromTag: string, toTag: string, cwd: string ): Promise<boolean> { try { // Check commit messages for breaking change indicators const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); const breakingKeywords = [ 'BREAKING CHANGE', 'breaking change', 'BREAKING:', '!:', 'breaking:', 'BC:', 'bc:' ]; const hasBreakingCommit = commits.some(commit => breakingKeywords.some(keyword => commit.message.toLowerCase().includes(keyword.toLowerCase()) ) ); if (hasBreakingCommit) return true; // Check for major version bump const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); return fromVersion.major !== toVersion.major; } catch { // Default to false if we can't determine return false; } } // Update planning and application /** Create an update plan for applying changes / export async function createUpdatePlan( fromVersion: string, toVersion: string, targetDir: string, options: UpdateOptions = {} ): Promise<UpdatePlan> { try { const diff = await getVersionDiff(fromVersion, toVersion, targetDir); const conflicts = await detectConflicts(diff, targetDir); const strategy: UpdateStrategy = { type: options.strategy?.type || 'merge', excludePaths: options.strategy?.excludePaths || [ '.git', 'node_modules', '.env', '.env.local' ], preserveFiles: options.strategy?.preserveFiles || [ 'package.json', 'README.md', '.gitignore' ], customMergers: options.strategy?.customMergers || {} }; return { fromVersion, toVersion, diff, conflicts, strategy, backupRequired: options.createBackup !== false || conflicts.length > 0 }; } catch (error) { throw new CLIError(`Failed to create update plan`, { code: 'UPDATE_PLAN_FAILED', cause: error instanceof Error ? error : undefined, context: { fromVersion, toVersion, targetDir } }); } } /** Detect potential conflicts in the update / async function detectConflicts( diff: VersionDiff, targetDir: string ): Promise<UpdateConflict[]> { const conflicts: UpdateConflict[] = []; for (const file of diff.files) { const filePath = path.join(targetDir, file.path); try { // Check if file exists and has local changes if (await exists(filePath)) { if (file.status === 'deleted') { conflicts.push({ file: file.path, type: 'deletion', description: `File exists locally but is deleted in the update`, resolution: 'manual' }); } else if (file.status === 'modified') { // Could check git status here to see if file has local changes const hasLocalChanges = await checkLocalChanges(filePath, targetDir); if (hasLocalChanges) { conflicts.push({ file: file.path, type: 'content', description: `File has both local and remote changes`, resolution: 'merge' }); } } } // Check file permissions const stats = await fs.stat(filePath).catch(() => null); if (stats && !stats.isFile()) { conflicts.push({ file: file.path, type: 'permission', description: `Path exists but is not a regular file`, resolution: 'skip' }); } } catch { // File doesn't exist - no conflict } } return conflicts; } /** Check if a file has local changes (not committed) / async function checkLocalChanges(filePath: string, cwd: string): Promise<boolean> { try { const relativePath = path.relative(cwd, filePath); const result = await execa('git', ['status', '--porcelain', relativePath], { cwd }); return result.stdout.trim().length > 0; } catch { return false; } } /** Apply an update plan / export async function applyUpdate( plan: UpdatePlan, targetDir: string, options: UpdateOptions = {} ): Promise<void> { if (options.dryRun) { logger.info('Dry run mode - no changes will be applied'); await logUpdatePlan(plan); return; } try { // Create backup if required if (plan.backupRequired && options.createBackup !== false) { await createBackup(targetDir); } // Apply changes based on strategy switch (plan.strategy.type) { case 'overwrite': await applyOverwriteStrategy(plan, targetDir, options); break; case 'merge': await applyMergeStrategy(plan, targetDir, options); break; case 'selective': await applySelectiveStrategy(plan, targetDir, options); break; } logger.success(`Successfully updated from ${plan.fromVersion} to ${plan.toVersion}`); } catch (error) { throw new CLIError(`Failed to apply update`, { code: 'UPDATE_APPLICATION_FAILED', cause: error instanceof Error ? error : undefined, context: { plan, targetDir, options } }); } } /** Create a backup of the target directory / async function createBackup(targetDir: string): Promise<string> { const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); const backupDir = `${targetDir}.backup.${timestamp}`; logger.info(`Creating backup at ${backupDir}`); try { await execa('cp', ['-r', targetDir, backupDir]); return backupDir; } catch { // Fallback for systems without cp await copyDirectory(targetDir, backupDir); return backupDir; } } /** Recursive directory copy fallback / async function copyDirectory(src: string, dest: string): Promise<void> { await ensureDir(dest); const items = await fs.readdir(src); for (const item of items) { const srcPath = path.join(src, item); const destPath = path.join(dest, item); const stats = await fs.stat(srcPath); if (stats.isDirectory()) { await copyDirectory(srcPath, destPath); } else { await copyFile(srcPath, destPath); } } } /** Apply overwrite strategy (replace everything) / async function applyOverwriteStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying overwrite strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } else if (file.status === 'added' || file.status === 'modified') { // This would require the source content - placeholder for now logger.info(`Would update: ${file.path}`); } } } /** Apply merge strategy (intelligent merging) / async function applyMergeStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying merge strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); // Handle conflicts based on their resolution strategy const conflict = plan.conflicts.find(c => c.file === file.path); if (conflict) { await handleConflict(conflict, targetPath, plan.strategy); } else { // No conflict - apply change directly if (file.status === 'added' || file.status === 'modified') { logger.info(`Would update: ${file.path}`); } else if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } } } } /** Apply selective strategy (user chooses what to update) / async function applySelectiveStrategy( _plan: UpdatePlan, _targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying selective strategy'); // Implementation would involve prompting user for each file change // This is a placeholder for the selective update logic logger.info('Selective strategy not yet fully implemented'); } /** Handle update conflicts / async function handleConflict( conflict: UpdateConflict, _targetPath: string, _strategy: UpdateStrategy ): Promise<void> { switch (conflict.resolution) { case 'skip': logger.warn(`Skipping conflicted file: ${conflict.file}`); break; case 'overwrite': logger.warn(`Overwriting conflicted file: ${conflict.file}`); // Implementation would overwrite the file break; case 'merge': logger.info(`Attempting to merge conflicted file: ${conflict.file}`); // Implementation would use git merge or custom merger break; case 'manual': logger.error(`Manual resolution required for: ${conflict.file}`); logger.info(`  ${conflict.description}`); break; } } /** Log the update plan details / async function logUpdatePlan(plan: UpdatePlan): Promise<void> { logger.info(`Update Plan: ${plan.fromVersion} â†’ ${plan.toVersion}`); logger.info(`Change Type: ${plan.diff.changeType}`); logger.info(`Breaking: ${plan.diff.breaking ? 'Yes' : 'No'}`); logger.info(`Strategy: ${plan.strategy.type}`); if (plan.diff.files.length > 0) { logger.info('\nFile Changes:'); for (const file of plan.diff.files) { const status = file.status.charAt(0).toUpperCase() + file.status.slice(1); logger.info(`  ${status}: ${file.path} (+${file.insertions}/-${file.deletions})`); } } if (plan.conflicts.length > 0) { logger.warn('\nConflicts:'); for (const conflict of plan.conflicts) { logger.warn(`  ${conflict.file}: ${conflict.description}`); } } if (plan.diff.commits.length > 0) { logger.info('\nCommits:'); for (const commit of plan.diff.commits.slice(0, 5)) { logger.info(`  ${commit.shortHash}: ${commit.message}`); } if (plan.diff.commits.length > 5) { logger.info(`  ... and ${plan.diff.commits.length - 5} more commits`); } } } // Utility functions for version management /** Get the latest tag in the repository / export async function getLatestTag(cwd: string = process.cwd()): Promise<string | null> { try { const result = await execa('git', ['describe', '--tags', '--abbrev=0'], { cwd, silent: true }); return result.stdout.trim() || null; } catch { return null; } } /** Get all tags in the repository, sorted by version / export async function getAllTags(cwd: string = process.cwd()): Promise<string[]> { try { const result = await execa('git', ['tag', '-l'], { cwd }); const tags = result.stdout.trim().split('\n').filter(Boolean); // Sort tags by semantic version return tags.sort((a, b) => { try { const versionA = parseVersion(a); const versionB = parseVersion(b); return compareVersions(versionA, versionB); } catch { // Fallback to string comparison for non-semver tags return a.localeCompare(b); } }); } catch { return []; } } /** Check if a tag exists in the repository / export async function tagExists(tag: string, cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', `refs/tags/${tag}`], { cwd, silent: true }); return true; } catch { return false; } } /** Create a new git tag

---

## createUpdatePlan

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export async function createUpdatePlan(
  fromVersion: string,
  toVersion: string,
  targetDir: string,
  options: UpdateOptions =
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation) / export function satisfiesRange(version: SemanticVersion, range: string): boolean { // Basic range patterns: "^1.2.3", "~1.2.3", ">=1.2.3", "1.2.3" if (range.startsWith('^')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('~')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && version.minor === targetVersion.minor && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) > 0; } if (range.startsWith('<=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) <= 0; } if (range.startsWith('<')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) < 0; } // Exact match const targetVersion = parseVersion(range); return compareVersions(version, targetVersion) === 0; } // Git-based version diffing /** Get detailed diff between two git tags/commits / export async function getVersionDiff( fromTag: string, toTag: string, cwd: string = process.cwd() ): Promise<VersionDiff> { const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); try { // Get commit history between versions const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); // Get file changes const files = await getFilesBetweenTags(fromTag, toTag, cwd); // Determine if this is a breaking change const breaking = await isBreakingChange(fromTag, toTag, cwd); return { from: fromVersion, to: toVersion, changeType: getChangeType(fromVersion, toVersion), files, commits, breaking }; } catch (error) { throw new CLIError(`Failed to get version diff from ${fromTag} to ${toTag}`, { code: 'VERSION_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { fromTag, toTag, cwd } }); } } /** Get commits between two git tags / async function getCommitsBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<git.GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await execa('git', ['log', `${fromTag}..${toTag}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message }; }); } catch (error) { throw new CLIError(`Failed to get commits between ${fromTag} and ${toTag}`, { code: 'GIT_COMMITS_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Get detailed file changes between two git tags / async function getFilesBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<FileDiff[]> { try { // Get file stats const statsResult = await execa('git', ['diff', '--numstat', `${fromTag}..${toTag}`], { cwd }); const stats = new Map<string, { insertions: number; deletions: number }>(); for (const line of statsResult.stdout.trim().split('\n').filter(Boolean)) { const [insertions, deletions, path] = line.split('\t'); stats.set(path, { insertions: insertions === '-' ? 0 : parseInt(insertions, 10), deletions: deletions === '-' ? 0 : parseInt(deletions, 10) }); } // Get file status (added, modified, deleted, renamed) const nameStatusResult = await execa('git', ['diff', '--name-status', `${fromTag}..${toTag}`], { cwd }); const files: FileDiff[] = []; for (const line of nameStatusResult.stdout.trim().split('\n').filter(Boolean)) { const parts = line.split('\t'); const status = parts[0]; const path = parts[1]; let fileStatus: FileDiff['status']; let oldPath: string | undefined; if (status === 'A') { fileStatus = 'added'; } else if (status === 'D') { fileStatus = 'deleted'; } else if (status === 'M') { fileStatus = 'modified'; } else if (status.startsWith('R')) { fileStatus = 'renamed'; oldPath = path; // For renames, the new path is in parts[2] const newPath = parts[2]; const fileStats = stats.get(newPath) || { insertions: 0, deletions: 0 }; files.push({ path: newPath, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); continue; } else { fileStatus = 'modified'; // Default for other statuses } const fileStats = stats.get(path) || { insertions: 0, deletions: 0 }; files.push({ path, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); } return files; } catch (error) { throw new CLIError(`Failed to get file changes between ${fromTag} and ${toTag}`, { code: 'GIT_FILES_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Heuristic to determine if changes are breaking / async function isBreakingChange( fromTag: string, toTag: string, cwd: string ): Promise<boolean> { try { // Check commit messages for breaking change indicators const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); const breakingKeywords = [ 'BREAKING CHANGE', 'breaking change', 'BREAKING:', '!:', 'breaking:', 'BC:', 'bc:' ]; const hasBreakingCommit = commits.some(commit => breakingKeywords.some(keyword => commit.message.toLowerCase().includes(keyword.toLowerCase()) ) ); if (hasBreakingCommit) return true; // Check for major version bump const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); return fromVersion.major !== toVersion.major; } catch { // Default to false if we can't determine return false; } } // Update planning and application /** Create an update plan for applying changes

---

## DependencyEdge

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## DependencyGraph

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## DependencyNode

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## detectPackageManager

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager>
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used

---

## detectWorkspaceType

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType>
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup

---

## discoverPackages

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function discoverPackages(
  cwd: string = process.cwd(),
  workspaceType?: WorkspaceType
): Promise<WorkspacePackage[]>
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace

---

## FileDiff

**Type**: `interface`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

---

## filterPackages

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export function filterPackages(
  packages: WorkspacePackage[], 
  filter: PackageFilter
): WorkspacePackage[]
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace / export async function discoverPackages( cwd: string = process.cwd(), workspaceType?: WorkspaceType ): Promise<WorkspacePackage[]> { const type = workspaceType || await detectWorkspaceType(cwd); const packages: WorkspacePackage[] = []; try { let packagePaths: string[] = []; switch (type) { case 'nx': packagePaths = await discoverNxPackages(cwd); break; case 'lerna': packagePaths = await discoverLernaPackages(cwd); break; case 'rush': packagePaths = await discoverRushPackages(cwd); break; case 'pnpm-workspace': case 'yarn-workspace': case 'npm-workspace': packagePaths = await discoverWorkspacesPackages(cwd); break; case 'turbo': // Turbo usually relies on other workspace configurations packagePaths = await discoverWorkspacesPackages(cwd); break; case 'multi-tool': // Try multiple discovery methods packagePaths = await discoverMultiToolPackages(cwd); break; case 'single-package': packagePaths = [cwd]; break; } // Process each discovered package for (const packagePath of packagePaths) { try { const pkg = await loadPackage(packagePath, cwd); if (pkg) { packages.push(pkg); } } catch (error) { workspaceLogger.warn(`Failed to load package at ${packagePath}: ${error}`); } } return packages; } catch (error) { throw new CLIError(`Failed to discover packages in workspace`, { code: 'WORKSPACE_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, workspaceType: type } }); } } /** Load a single package from a directory / async function loadPackage( packagePath: string, workspaceRoot: string ): Promise<WorkspacePackage | null> { const packageJsonPath = path.join(packagePath, 'package.json'); if (!await exists(packageJsonPath)) { return null; } try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (!packageJson.name) { workspaceLogger.warn(`Package at ${packagePath} has no name field`); return null; } const dependencies = new Map(Object.entries(packageJson.dependencies || {})); const devDependencies = new Map(Object.entries(packageJson.devDependencies || {})); const peerDependencies = new Map(Object.entries(packageJson.peerDependencies || {})); const scripts = new Map(Object.entries(packageJson.scripts || {})); return { name: packageJson.name, version: packageJson.version || '0.0.0', path: packagePath, relativePath: path.relative(workspaceRoot, packagePath), packageJson, dependencies, devDependencies, peerDependencies, scripts, isPrivate: packageJson.private || false, workspaceDependencies: [] // Will be populated later }; } catch (error) { throw new CLIError(`Failed to parse package.json at ${packagePath}`, { code: 'PACKAGE_JSON_PARSE_FAILED', cause: error instanceof Error ? error : undefined, context: { packagePath } }); } } // Package discovery methods for different workspace types async function discoverNxPackages(cwd: string): Promise<string[]> { const paths: string[] = []; try { // Try nx.json first const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { const nxConfig: NxConfiguration = JSON.parse(await readFile(nxJsonPath)); if (nxConfig.projects) { for (const [, projectConfig] of Object.entries(nxConfig.projects)) { if (typeof projectConfig === 'string') { paths.push(path.join(cwd, projectConfig)); } else if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, projectConfig.root as string)); } } } } // Try workspace.json as fallback const workspaceJsonPath = path.join(cwd, 'workspace.json'); if (paths.length === 0 && await exists(workspaceJsonPath)) { const workspaceConfig = JSON.parse(await readFile(workspaceJsonPath)); if (workspaceConfig.projects) { for (const [, projectConfig] of Object.entries(workspaceConfig.projects)) { if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, (projectConfig as any).root)); } } } } // If no explicit projects, scan common patterns if (paths.length === 0) { const patterns = ['apps/*', 'libs/*', 'packages/*', 'projects/*']; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } } return paths; } catch (error) { throw new CLIError('Failed to discover Nx packages', { code: 'NX_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverLernaPackages(cwd: string): Promise<string[]> { try { const lernaJsonPath = path.join(cwd, 'lerna.json'); const lernaConfig: LernaConfiguration = JSON.parse(await readFile(lernaJsonPath)); const patterns = lernaConfig.packages || ['packages/*']; const paths: string[] = []; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover Lerna packages', { code: 'LERNA_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverRushPackages(cwd: string): Promise<string[]> { try { const rushJsonPath = path.join(cwd, 'rush.json'); const rushConfig: RushConfiguration = JSON.parse(await readFile(rushJsonPath)); return rushConfig.projects.map(project => path.join(cwd, project.projectFolder) ); } catch (error) { throw new CLIError('Failed to discover Rush packages', { code: 'RUSH_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverWorkspacesPackages(cwd: string): Promise<string[]> { try { const packageJsonPath = path.join(cwd, 'package.json'); const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); let workspacePatterns: string[] = []; if (packageJson.workspaces) { if (Array.isArray(packageJson.workspaces)) { workspacePatterns = packageJson.workspaces; } else if (packageJson.workspaces.packages) { workspacePatterns = packageJson.workspaces.packages; } } // Check pnpm-workspace.yaml const pnpmWorkspacePath = path.join(cwd, 'pnpm-workspace.yaml'); if (workspacePatterns.length === 0 && await exists(pnpmWorkspacePath)) { try { // Simple YAML parsing for packages field const yamlContent = await readFile(pnpmWorkspacePath); const packagesMatch = yamlContent.match(/packages:\s*\n((?:\s*-\s*.+\n?)*)/); if (packagesMatch) { workspacePatterns = packagesMatch[1] .split('\n') .map(line => line.trim().replace(/^-\s*/, '').replace(/['"](.+)['"]/, '$1')) .filter(Boolean); } } catch (error) { workspaceLogger.warn(`Failed to parse pnpm-workspace.yaml: ${error}`); } } if (workspacePatterns.length === 0) { // Default patterns if none specified workspacePatterns = ['packages/*']; } const paths: string[] = []; for (const pattern of workspacePatterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover workspace packages', { code: 'WORKSPACES_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverMultiToolPackages(cwd: string): Promise<string[]> { const allPaths: Set<string> = new Set(); // Try all discovery methods and combine results const discoveryMethods = [ () => discoverNxPackages(cwd), () => discoverLernaPackages(cwd), () => discoverWorkspacesPackages(cwd), () => discoverRushPackages(cwd) ]; for (const method of discoveryMethods) { try { const paths = await method(); paths.forEach(p => allPaths.add(p)); } catch { // Ignore errors from individual discovery methods } } return Array.from(allPaths); } /** Load complete workspace configuration / export async function loadWorkspace(cwd: string = process.cwd()): Promise<WorkspaceConfiguration> { try { const workspaceType = await detectWorkspaceType(cwd); const packageManager = await detectPackageManager(cwd); const packages = await discoverPackages(cwd, workspaceType); const tools = await loadWorkspaceTools(cwd); // Create package map for quick lookups const packageMap = new Map<string, WorkspacePackage>(); packages.forEach(pkg => packageMap.set(pkg.name, pkg)); // Build dependency graph const dependencyGraph = buildDependencyGraph(packages); // Load workspace-level scripts const scripts = await loadWorkspaceScripts(cwd); return { type: workspaceType, root: cwd, packages, packageMap, dependencyGraph, tools, packageManager, scripts }; } catch (error) { throw new CLIError(`Failed to load workspace configuration`, { code: 'WORKSPACE_LOAD_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } /** Load workspace tools configuration / async function loadWorkspaceTools(cwd: string): Promise<WorkspaceTools> { const tools: WorkspaceTools = { hasNx: false, hasLerna: false, hasRush: false, hasTurbo: false, hasWorkspaces: false, configurations: {} }; // Check for Nx const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { tools.hasNx = true; try { tools.configurations.nx = JSON.parse(await readFile(nxJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse nx.json: ${error}`); } } // Check for Lerna const lernaJsonPath = path.join(cwd, 'lerna.json'); if (await exists(lernaJsonPath)) { tools.hasLerna = true; try { tools.configurations.lerna = JSON.parse(await readFile(lernaJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse lerna.json: ${error}`); } } // Check for Rush const rushJsonPath = path.join(cwd, 'rush.json'); if (await exists(rushJsonPath)) { tools.hasRush = true; try { tools.configurations.rush = JSON.parse(await readFile(rushJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse rush.json: ${error}`); } } // Check for Turbo const turboJsonPath = path.join(cwd, 'turbo.json'); if (await exists(turboJsonPath)) { tools.hasTurbo = true; try { tools.configurations.turbo = JSON.parse(await readFile(turboJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse turbo.json: ${error}`); } } // Check for workspaces const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { tools.hasWorkspaces = true; if (Array.isArray(packageJson.workspaces)) { tools.configurations.workspaces = { packages: packageJson.workspaces }; } else if (packageJson.workspaces.packages) { tools.configurations.workspaces = packageJson.workspaces; } } } catch (error) { workspaceLogger.warn(`Failed to parse package.json: ${error}`); } } return tools; } /** Load workspace-level scripts / async function loadWorkspaceScripts(cwd: string): Promise<Map<string, string>> { const scripts = new Map<string, string>(); try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.scripts) { Object.entries(packageJson.scripts).forEach(([name, script]) => { scripts.set(name, script); }); } } } catch (error) { workspaceLogger.warn(`Failed to load workspace scripts: ${error}`); } return scripts; } /** Build dependency graph for workspace packages / function buildDependencyGraph(packages: WorkspacePackage[]): DependencyGraph { const nodes = new Map<string, DependencyNode>(); const edges: DependencyEdge[] = []; const packageNames = new Set(packages.map(pkg => pkg.name)); // Initialize nodes packages.forEach(pkg => { nodes.set(pkg.name, { name: pkg.name, package: pkg, dependencies: new Set(), dependents: new Set(), depth: 0 }); }); // Build edges and populate workspace dependencies packages.forEach(pkg => { const node = nodes.get(pkg.name)!; // Process dependencies ['dependencies', 'devDependencies', 'peerDependencies'].forEach(depType => { const deps = pkg[depType as keyof WorkspacePackage] as Map<string, string> | undefined; if (!deps) return; deps.forEach((_, depName) => { if (packageNames.has(depName)) { // This is a workspace dependency pkg.workspaceDependencies.push(depName); node.dependencies.add(depName); const targetNode = nodes.get(depName); if (targetNode) { targetNode.dependents.add(pkg.name); } edges.push({ from: pkg.name, to: depName, type: depType as 'dependencies' | 'devDependencies' | 'peerDependencies' }); } }); }); }); // Calculate depths (topological sort) const topologicalOrder = topologicalSort(nodes); // Detect circular dependencies const circularDependencies = detectCircularDependencies(nodes); return { nodes, edges, topologicalOrder, circularDependencies }; } /** Perform topological sort on dependency graph / function topologicalSort(nodes: Map<string, DependencyNode>): string[] { const visited = new Set<string>(); const temp = new Set<string>(); const result: string[] = []; function visit(nodeName: string): void { if (temp.has(nodeName)) return; // Circular dependency if (visited.has(nodeName)) return; temp.add(nodeName); const node = nodes.get(nodeName); if (node) { node.dependencies.forEach(depName => visit(depName)); node.depth = Math.max(node.depth, ...Array.from(node.dependencies).map(dep => (nodes.get(dep)?.depth || 0) + 1 )); } temp.delete(nodeName); visited.add(nodeName); result.push(nodeName); } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { visit(nodeName); } }); return result; } /** Detect circular dependencies in the graph / function detectCircularDependencies(nodes: Map<string, DependencyNode>): string[][] { const visited = new Set<string>(); const recursionStack = new Set<string>(); const cycles: string[][] = []; const currentPath: string[] = []; function dfs(nodeName: string): boolean { visited.add(nodeName); recursionStack.add(nodeName); currentPath.push(nodeName); const node = nodes.get(nodeName); if (node) { for (const depName of node.dependencies) { if (!visited.has(depName)) { if (dfs(depName)) return true; } else if (recursionStack.has(depName)) { // Found a cycle const cycleStart = currentPath.indexOf(depName); cycles.push(currentPath.slice(cycleStart).concat([depName])); return true; } } } currentPath.pop(); recursionStack.delete(nodeName); return false; } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { dfs(nodeName); } }); return cycles; } // Batch operations and utility functions /** Filter packages based on criteria

---

## getAffectedPackages

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function getAffectedPackages(
  workspace: WorkspaceConfiguration,
  options: ChangeDetectionOptions =
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace / export async function discoverPackages( cwd: string = process.cwd(), workspaceType?: WorkspaceType ): Promise<WorkspacePackage[]> { const type = workspaceType || await detectWorkspaceType(cwd); const packages: WorkspacePackage[] = []; try { let packagePaths: string[] = []; switch (type) { case 'nx': packagePaths = await discoverNxPackages(cwd); break; case 'lerna': packagePaths = await discoverLernaPackages(cwd); break; case 'rush': packagePaths = await discoverRushPackages(cwd); break; case 'pnpm-workspace': case 'yarn-workspace': case 'npm-workspace': packagePaths = await discoverWorkspacesPackages(cwd); break; case 'turbo': // Turbo usually relies on other workspace configurations packagePaths = await discoverWorkspacesPackages(cwd); break; case 'multi-tool': // Try multiple discovery methods packagePaths = await discoverMultiToolPackages(cwd); break; case 'single-package': packagePaths = [cwd]; break; } // Process each discovered package for (const packagePath of packagePaths) { try { const pkg = await loadPackage(packagePath, cwd); if (pkg) { packages.push(pkg); } } catch (error) { workspaceLogger.warn(`Failed to load package at ${packagePath}: ${error}`); } } return packages; } catch (error) { throw new CLIError(`Failed to discover packages in workspace`, { code: 'WORKSPACE_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, workspaceType: type } }); } } /** Load a single package from a directory / async function loadPackage( packagePath: string, workspaceRoot: string ): Promise<WorkspacePackage | null> { const packageJsonPath = path.join(packagePath, 'package.json'); if (!await exists(packageJsonPath)) { return null; } try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (!packageJson.name) { workspaceLogger.warn(`Package at ${packagePath} has no name field`); return null; } const dependencies = new Map(Object.entries(packageJson.dependencies || {})); const devDependencies = new Map(Object.entries(packageJson.devDependencies || {})); const peerDependencies = new Map(Object.entries(packageJson.peerDependencies || {})); const scripts = new Map(Object.entries(packageJson.scripts || {})); return { name: packageJson.name, version: packageJson.version || '0.0.0', path: packagePath, relativePath: path.relative(workspaceRoot, packagePath), packageJson, dependencies, devDependencies, peerDependencies, scripts, isPrivate: packageJson.private || false, workspaceDependencies: [] // Will be populated later }; } catch (error) { throw new CLIError(`Failed to parse package.json at ${packagePath}`, { code: 'PACKAGE_JSON_PARSE_FAILED', cause: error instanceof Error ? error : undefined, context: { packagePath } }); } } // Package discovery methods for different workspace types async function discoverNxPackages(cwd: string): Promise<string[]> { const paths: string[] = []; try { // Try nx.json first const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { const nxConfig: NxConfiguration = JSON.parse(await readFile(nxJsonPath)); if (nxConfig.projects) { for (const [, projectConfig] of Object.entries(nxConfig.projects)) { if (typeof projectConfig === 'string') { paths.push(path.join(cwd, projectConfig)); } else if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, projectConfig.root as string)); } } } } // Try workspace.json as fallback const workspaceJsonPath = path.join(cwd, 'workspace.json'); if (paths.length === 0 && await exists(workspaceJsonPath)) { const workspaceConfig = JSON.parse(await readFile(workspaceJsonPath)); if (workspaceConfig.projects) { for (const [, projectConfig] of Object.entries(workspaceConfig.projects)) { if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, (projectConfig as any).root)); } } } } // If no explicit projects, scan common patterns if (paths.length === 0) { const patterns = ['apps/*', 'libs/*', 'packages/*', 'projects/*']; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } } return paths; } catch (error) { throw new CLIError('Failed to discover Nx packages', { code: 'NX_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverLernaPackages(cwd: string): Promise<string[]> { try { const lernaJsonPath = path.join(cwd, 'lerna.json'); const lernaConfig: LernaConfiguration = JSON.parse(await readFile(lernaJsonPath)); const patterns = lernaConfig.packages || ['packages/*']; const paths: string[] = []; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover Lerna packages', { code: 'LERNA_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverRushPackages(cwd: string): Promise<string[]> { try { const rushJsonPath = path.join(cwd, 'rush.json'); const rushConfig: RushConfiguration = JSON.parse(await readFile(rushJsonPath)); return rushConfig.projects.map(project => path.join(cwd, project.projectFolder) ); } catch (error) { throw new CLIError('Failed to discover Rush packages', { code: 'RUSH_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverWorkspacesPackages(cwd: string): Promise<string[]> { try { const packageJsonPath = path.join(cwd, 'package.json'); const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); let workspacePatterns: string[] = []; if (packageJson.workspaces) { if (Array.isArray(packageJson.workspaces)) { workspacePatterns = packageJson.workspaces; } else if (packageJson.workspaces.packages) { workspacePatterns = packageJson.workspaces.packages; } } // Check pnpm-workspace.yaml const pnpmWorkspacePath = path.join(cwd, 'pnpm-workspace.yaml'); if (workspacePatterns.length === 0 && await exists(pnpmWorkspacePath)) { try { // Simple YAML parsing for packages field const yamlContent = await readFile(pnpmWorkspacePath); const packagesMatch = yamlContent.match(/packages:\s*\n((?:\s*-\s*.+\n?)*)/); if (packagesMatch) { workspacePatterns = packagesMatch[1] .split('\n') .map(line => line.trim().replace(/^-\s*/, '').replace(/['"](.+)['"]/, '$1')) .filter(Boolean); } } catch (error) { workspaceLogger.warn(`Failed to parse pnpm-workspace.yaml: ${error}`); } } if (workspacePatterns.length === 0) { // Default patterns if none specified workspacePatterns = ['packages/*']; } const paths: string[] = []; for (const pattern of workspacePatterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover workspace packages', { code: 'WORKSPACES_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverMultiToolPackages(cwd: string): Promise<string[]> { const allPaths: Set<string> = new Set(); // Try all discovery methods and combine results const discoveryMethods = [ () => discoverNxPackages(cwd), () => discoverLernaPackages(cwd), () => discoverWorkspacesPackages(cwd), () => discoverRushPackages(cwd) ]; for (const method of discoveryMethods) { try { const paths = await method(); paths.forEach(p => allPaths.add(p)); } catch { // Ignore errors from individual discovery methods } } return Array.from(allPaths); } /** Load complete workspace configuration / export async function loadWorkspace(cwd: string = process.cwd()): Promise<WorkspaceConfiguration> { try { const workspaceType = await detectWorkspaceType(cwd); const packageManager = await detectPackageManager(cwd); const packages = await discoverPackages(cwd, workspaceType); const tools = await loadWorkspaceTools(cwd); // Create package map for quick lookups const packageMap = new Map<string, WorkspacePackage>(); packages.forEach(pkg => packageMap.set(pkg.name, pkg)); // Build dependency graph const dependencyGraph = buildDependencyGraph(packages); // Load workspace-level scripts const scripts = await loadWorkspaceScripts(cwd); return { type: workspaceType, root: cwd, packages, packageMap, dependencyGraph, tools, packageManager, scripts }; } catch (error) { throw new CLIError(`Failed to load workspace configuration`, { code: 'WORKSPACE_LOAD_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } /** Load workspace tools configuration / async function loadWorkspaceTools(cwd: string): Promise<WorkspaceTools> { const tools: WorkspaceTools = { hasNx: false, hasLerna: false, hasRush: false, hasTurbo: false, hasWorkspaces: false, configurations: {} }; // Check for Nx const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { tools.hasNx = true; try { tools.configurations.nx = JSON.parse(await readFile(nxJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse nx.json: ${error}`); } } // Check for Lerna const lernaJsonPath = path.join(cwd, 'lerna.json'); if (await exists(lernaJsonPath)) { tools.hasLerna = true; try { tools.configurations.lerna = JSON.parse(await readFile(lernaJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse lerna.json: ${error}`); } } // Check for Rush const rushJsonPath = path.join(cwd, 'rush.json'); if (await exists(rushJsonPath)) { tools.hasRush = true; try { tools.configurations.rush = JSON.parse(await readFile(rushJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse rush.json: ${error}`); } } // Check for Turbo const turboJsonPath = path.join(cwd, 'turbo.json'); if (await exists(turboJsonPath)) { tools.hasTurbo = true; try { tools.configurations.turbo = JSON.parse(await readFile(turboJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse turbo.json: ${error}`); } } // Check for workspaces const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { tools.hasWorkspaces = true; if (Array.isArray(packageJson.workspaces)) { tools.configurations.workspaces = { packages: packageJson.workspaces }; } else if (packageJson.workspaces.packages) { tools.configurations.workspaces = packageJson.workspaces; } } } catch (error) { workspaceLogger.warn(`Failed to parse package.json: ${error}`); } } return tools; } /** Load workspace-level scripts / async function loadWorkspaceScripts(cwd: string): Promise<Map<string, string>> { const scripts = new Map<string, string>(); try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.scripts) { Object.entries(packageJson.scripts).forEach(([name, script]) => { scripts.set(name, script); }); } } } catch (error) { workspaceLogger.warn(`Failed to load workspace scripts: ${error}`); } return scripts; } /** Build dependency graph for workspace packages / function buildDependencyGraph(packages: WorkspacePackage[]): DependencyGraph { const nodes = new Map<string, DependencyNode>(); const edges: DependencyEdge[] = []; const packageNames = new Set(packages.map(pkg => pkg.name)); // Initialize nodes packages.forEach(pkg => { nodes.set(pkg.name, { name: pkg.name, package: pkg, dependencies: new Set(), dependents: new Set(), depth: 0 }); }); // Build edges and populate workspace dependencies packages.forEach(pkg => { const node = nodes.get(pkg.name)!; // Process dependencies ['dependencies', 'devDependencies', 'peerDependencies'].forEach(depType => { const deps = pkg[depType as keyof WorkspacePackage] as Map<string, string> | undefined; if (!deps) return; deps.forEach((_, depName) => { if (packageNames.has(depName)) { // This is a workspace dependency pkg.workspaceDependencies.push(depName); node.dependencies.add(depName); const targetNode = nodes.get(depName); if (targetNode) { targetNode.dependents.add(pkg.name); } edges.push({ from: pkg.name, to: depName, type: depType as 'dependencies' | 'devDependencies' | 'peerDependencies' }); } }); }); }); // Calculate depths (topological sort) const topologicalOrder = topologicalSort(nodes); // Detect circular dependencies const circularDependencies = detectCircularDependencies(nodes); return { nodes, edges, topologicalOrder, circularDependencies }; } /** Perform topological sort on dependency graph / function topologicalSort(nodes: Map<string, DependencyNode>): string[] { const visited = new Set<string>(); const temp = new Set<string>(); const result: string[] = []; function visit(nodeName: string): void { if (temp.has(nodeName)) return; // Circular dependency if (visited.has(nodeName)) return; temp.add(nodeName); const node = nodes.get(nodeName); if (node) { node.dependencies.forEach(depName => visit(depName)); node.depth = Math.max(node.depth, ...Array.from(node.dependencies).map(dep => (nodes.get(dep)?.depth || 0) + 1 )); } temp.delete(nodeName); visited.add(nodeName); result.push(nodeName); } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { visit(nodeName); } }); return result; } /** Detect circular dependencies in the graph / function detectCircularDependencies(nodes: Map<string, DependencyNode>): string[][] { const visited = new Set<string>(); const recursionStack = new Set<string>(); const cycles: string[][] = []; const currentPath: string[] = []; function dfs(nodeName: string): boolean { visited.add(nodeName); recursionStack.add(nodeName); currentPath.push(nodeName); const node = nodes.get(nodeName); if (node) { for (const depName of node.dependencies) { if (!visited.has(depName)) { if (dfs(depName)) return true; } else if (recursionStack.has(depName)) { // Found a cycle const cycleStart = currentPath.indexOf(depName); cycles.push(currentPath.slice(cycleStart).concat([depName])); return true; } } } currentPath.pop(); recursionStack.delete(nodeName); return false; } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { dfs(nodeName); } }); return cycles; } // Batch operations and utility functions /** Filter packages based on criteria / export function filterPackages( packages: WorkspacePackage[], filter: PackageFilter ): WorkspacePackage[] { return packages.filter(pkg => { if (filter.names && !filter.names.includes(pkg.name)) return false; if (filter.paths && !filter.paths.some(p => pkg.relativePath.includes(p))) return false; if (filter.hasScript && !pkg.scripts.has(filter.hasScript)) return false; if (filter.hasDependency) { const hasDep = pkg.dependencies.has(filter.hasDependency) || pkg.devDependencies.has(filter.hasDependency) || pkg.peerDependencies.has(filter.hasDependency); if (!hasDep) return false; } if (filter.isPrivate !== undefined && pkg.isPrivate !== filter.isPrivate) return false; if (filter.custom && !filter.custom(pkg)) return false; return true; }); } /** Run a script across multiple packages / export async function runScript( packages: WorkspacePackage[], scriptName: string, options: BatchOperationOptions = {} ): Promise<Map<string, { success: boolean; output?: string; error?: Error }>> { const { concurrency = 4, continueOnError = false, filter, scope, ignore = [], onProgress, onPackageComplete, onPackageError } = options; const results = new Map<string, { success: boolean; output?: string; error?: Error }>(); let filteredPackages = packages; // Apply filters if (filter) { filteredPackages = filterPackages(filteredPackages, filter); } if (scope) { filteredPackages = filteredPackages.filter(pkg => scope.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } if (ignore.length > 0) { filteredPackages = filteredPackages.filter(pkg => !ignore.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } // Filter packages that have the script const packagesWithScript = filteredPackages.filter(pkg => pkg.scripts.has(scriptName)); if (packagesWithScript.length === 0) { workspaceLogger.warn(`No packages found with script "${scriptName}"`); return results; } // Import execa here to avoid circular dependencies const { execa } = await import('../core/execution/execa.js'); let completed = 0; const total = packagesWithScript.length; const runPackageScript = async (pkg: WorkspacePackage): Promise<void> => { try { // Get the script command (we know it exists from the filter) pkg.scripts.get(scriptName)!; const result = await execa('npm', ['run', scriptName], { cwd: pkg.path, silent: true }); results.set(pkg.name, { success: true, output: result.stdout }); onPackageComplete?.(pkg, result); } catch (error) { const err = error instanceof Error ? error : new Error(String(error)); results.set(pkg.name, { success: false, error: err }); onPackageError?.(pkg, err); if (!continueOnError) { throw err; } } finally { completed++; onProgress?.(completed, total, pkg.name); } }; // Execute with concurrency limit const semaphore = Array(concurrency).fill(null); const packageQueue = [...packagesWithScript]; await Promise.all( semaphore.map(async () => { while (packageQueue.length > 0) { const pkg = packageQueue.shift(); if (pkg) { await runPackageScript(pkg); } } }) ); return results; } /** Install dependencies for packages / export async function installDependencies( packages: WorkspacePackage[], packageManager: PackageManager = 'npm', options: BatchOperationOptions = {} ): Promise<Map<string, { success: boolean; output?: string; error?: Error }>> { const { execa } = await import('../core/execution/execa.js'); const results = new Map<string, { success: boolean; output?: string; error?: Error }>(); let filteredPackages = packages; if (options.filter) { filteredPackages = filterPackages(filteredPackages, options.filter); } const commands: Record<PackageManager, string[]> = { npm: ['npm', 'install'], yarn: ['yarn', 'install'], pnpm: ['pnpm', 'install'], bun: ['bun', 'install'], rush: ['rush', 'install'], auto: ['npm', 'install'] // fallback }; const [cmd, ...args] = commands[packageManager]; let completed = 0; const total = filteredPackages.length; for (const pkg of filteredPackages) { try { const result = await execa(cmd, args, { cwd: pkg.path, silent: true }); results.set(pkg.name, { success: true, output: result.stdout }); options.onPackageComplete?.(pkg, result); } catch (error) { const err = error instanceof Error ? error : new Error(String(error)); results.set(pkg.name, { success: false, error: err }); options.onPackageError?.(pkg, err); if (!options.continueOnError) { throw err; } } finally { completed++; options.onProgress?.(completed, total, pkg.name); } } return results; } /** Get packages affected by changes since a specific commit/branch

---

## getAllTags

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export async function getAllTags(cwd: string = process.cwd()): Promise<string[]>
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation) / export function satisfiesRange(version: SemanticVersion, range: string): boolean { // Basic range patterns: "^1.2.3", "~1.2.3", ">=1.2.3", "1.2.3" if (range.startsWith('^')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('~')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && version.minor === targetVersion.minor && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) > 0; } if (range.startsWith('<=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) <= 0; } if (range.startsWith('<')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) < 0; } // Exact match const targetVersion = parseVersion(range); return compareVersions(version, targetVersion) === 0; } // Git-based version diffing /** Get detailed diff between two git tags/commits / export async function getVersionDiff( fromTag: string, toTag: string, cwd: string = process.cwd() ): Promise<VersionDiff> { const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); try { // Get commit history between versions const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); // Get file changes const files = await getFilesBetweenTags(fromTag, toTag, cwd); // Determine if this is a breaking change const breaking = await isBreakingChange(fromTag, toTag, cwd); return { from: fromVersion, to: toVersion, changeType: getChangeType(fromVersion, toVersion), files, commits, breaking }; } catch (error) { throw new CLIError(`Failed to get version diff from ${fromTag} to ${toTag}`, { code: 'VERSION_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { fromTag, toTag, cwd } }); } } /** Get commits between two git tags / async function getCommitsBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<git.GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await execa('git', ['log', `${fromTag}..${toTag}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message }; }); } catch (error) { throw new CLIError(`Failed to get commits between ${fromTag} and ${toTag}`, { code: 'GIT_COMMITS_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Get detailed file changes between two git tags / async function getFilesBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<FileDiff[]> { try { // Get file stats const statsResult = await execa('git', ['diff', '--numstat', `${fromTag}..${toTag}`], { cwd }); const stats = new Map<string, { insertions: number; deletions: number }>(); for (const line of statsResult.stdout.trim().split('\n').filter(Boolean)) { const [insertions, deletions, path] = line.split('\t'); stats.set(path, { insertions: insertions === '-' ? 0 : parseInt(insertions, 10), deletions: deletions === '-' ? 0 : parseInt(deletions, 10) }); } // Get file status (added, modified, deleted, renamed) const nameStatusResult = await execa('git', ['diff', '--name-status', `${fromTag}..${toTag}`], { cwd }); const files: FileDiff[] = []; for (const line of nameStatusResult.stdout.trim().split('\n').filter(Boolean)) { const parts = line.split('\t'); const status = parts[0]; const path = parts[1]; let fileStatus: FileDiff['status']; let oldPath: string | undefined; if (status === 'A') { fileStatus = 'added'; } else if (status === 'D') { fileStatus = 'deleted'; } else if (status === 'M') { fileStatus = 'modified'; } else if (status.startsWith('R')) { fileStatus = 'renamed'; oldPath = path; // For renames, the new path is in parts[2] const newPath = parts[2]; const fileStats = stats.get(newPath) || { insertions: 0, deletions: 0 }; files.push({ path: newPath, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); continue; } else { fileStatus = 'modified'; // Default for other statuses } const fileStats = stats.get(path) || { insertions: 0, deletions: 0 }; files.push({ path, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); } return files; } catch (error) { throw new CLIError(`Failed to get file changes between ${fromTag} and ${toTag}`, { code: 'GIT_FILES_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Heuristic to determine if changes are breaking / async function isBreakingChange( fromTag: string, toTag: string, cwd: string ): Promise<boolean> { try { // Check commit messages for breaking change indicators const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); const breakingKeywords = [ 'BREAKING CHANGE', 'breaking change', 'BREAKING:', '!:', 'breaking:', 'BC:', 'bc:' ]; const hasBreakingCommit = commits.some(commit => breakingKeywords.some(keyword => commit.message.toLowerCase().includes(keyword.toLowerCase()) ) ); if (hasBreakingCommit) return true; // Check for major version bump const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); return fromVersion.major !== toVersion.major; } catch { // Default to false if we can't determine return false; } } // Update planning and application /** Create an update plan for applying changes / export async function createUpdatePlan( fromVersion: string, toVersion: string, targetDir: string, options: UpdateOptions = {} ): Promise<UpdatePlan> { try { const diff = await getVersionDiff(fromVersion, toVersion, targetDir); const conflicts = await detectConflicts(diff, targetDir); const strategy: UpdateStrategy = { type: options.strategy?.type || 'merge', excludePaths: options.strategy?.excludePaths || [ '.git', 'node_modules', '.env', '.env.local' ], preserveFiles: options.strategy?.preserveFiles || [ 'package.json', 'README.md', '.gitignore' ], customMergers: options.strategy?.customMergers || {} }; return { fromVersion, toVersion, diff, conflicts, strategy, backupRequired: options.createBackup !== false || conflicts.length > 0 }; } catch (error) { throw new CLIError(`Failed to create update plan`, { code: 'UPDATE_PLAN_FAILED', cause: error instanceof Error ? error : undefined, context: { fromVersion, toVersion, targetDir } }); } } /** Detect potential conflicts in the update / async function detectConflicts( diff: VersionDiff, targetDir: string ): Promise<UpdateConflict[]> { const conflicts: UpdateConflict[] = []; for (const file of diff.files) { const filePath = path.join(targetDir, file.path); try { // Check if file exists and has local changes if (await exists(filePath)) { if (file.status === 'deleted') { conflicts.push({ file: file.path, type: 'deletion', description: `File exists locally but is deleted in the update`, resolution: 'manual' }); } else if (file.status === 'modified') { // Could check git status here to see if file has local changes const hasLocalChanges = await checkLocalChanges(filePath, targetDir); if (hasLocalChanges) { conflicts.push({ file: file.path, type: 'content', description: `File has both local and remote changes`, resolution: 'merge' }); } } } // Check file permissions const stats = await fs.stat(filePath).catch(() => null); if (stats && !stats.isFile()) { conflicts.push({ file: file.path, type: 'permission', description: `Path exists but is not a regular file`, resolution: 'skip' }); } } catch { // File doesn't exist - no conflict } } return conflicts; } /** Check if a file has local changes (not committed) / async function checkLocalChanges(filePath: string, cwd: string): Promise<boolean> { try { const relativePath = path.relative(cwd, filePath); const result = await execa('git', ['status', '--porcelain', relativePath], { cwd }); return result.stdout.trim().length > 0; } catch { return false; } } /** Apply an update plan / export async function applyUpdate( plan: UpdatePlan, targetDir: string, options: UpdateOptions = {} ): Promise<void> { if (options.dryRun) { logger.info('Dry run mode - no changes will be applied'); await logUpdatePlan(plan); return; } try { // Create backup if required if (plan.backupRequired && options.createBackup !== false) { await createBackup(targetDir); } // Apply changes based on strategy switch (plan.strategy.type) { case 'overwrite': await applyOverwriteStrategy(plan, targetDir, options); break; case 'merge': await applyMergeStrategy(plan, targetDir, options); break; case 'selective': await applySelectiveStrategy(plan, targetDir, options); break; } logger.success(`Successfully updated from ${plan.fromVersion} to ${plan.toVersion}`); } catch (error) { throw new CLIError(`Failed to apply update`, { code: 'UPDATE_APPLICATION_FAILED', cause: error instanceof Error ? error : undefined, context: { plan, targetDir, options } }); } } /** Create a backup of the target directory / async function createBackup(targetDir: string): Promise<string> { const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); const backupDir = `${targetDir}.backup.${timestamp}`; logger.info(`Creating backup at ${backupDir}`); try { await execa('cp', ['-r', targetDir, backupDir]); return backupDir; } catch { // Fallback for systems without cp await copyDirectory(targetDir, backupDir); return backupDir; } } /** Recursive directory copy fallback / async function copyDirectory(src: string, dest: string): Promise<void> { await ensureDir(dest); const items = await fs.readdir(src); for (const item of items) { const srcPath = path.join(src, item); const destPath = path.join(dest, item); const stats = await fs.stat(srcPath); if (stats.isDirectory()) { await copyDirectory(srcPath, destPath); } else { await copyFile(srcPath, destPath); } } } /** Apply overwrite strategy (replace everything) / async function applyOverwriteStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying overwrite strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } else if (file.status === 'added' || file.status === 'modified') { // This would require the source content - placeholder for now logger.info(`Would update: ${file.path}`); } } } /** Apply merge strategy (intelligent merging) / async function applyMergeStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying merge strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); // Handle conflicts based on their resolution strategy const conflict = plan.conflicts.find(c => c.file === file.path); if (conflict) { await handleConflict(conflict, targetPath, plan.strategy); } else { // No conflict - apply change directly if (file.status === 'added' || file.status === 'modified') { logger.info(`Would update: ${file.path}`); } else if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } } } } /** Apply selective strategy (user chooses what to update) / async function applySelectiveStrategy( _plan: UpdatePlan, _targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying selective strategy'); // Implementation would involve prompting user for each file change // This is a placeholder for the selective update logic logger.info('Selective strategy not yet fully implemented'); } /** Handle update conflicts / async function handleConflict( conflict: UpdateConflict, _targetPath: string, _strategy: UpdateStrategy ): Promise<void> { switch (conflict.resolution) { case 'skip': logger.warn(`Skipping conflicted file: ${conflict.file}`); break; case 'overwrite': logger.warn(`Overwriting conflicted file: ${conflict.file}`); // Implementation would overwrite the file break; case 'merge': logger.info(`Attempting to merge conflicted file: ${conflict.file}`); // Implementation would use git merge or custom merger break; case 'manual': logger.error(`Manual resolution required for: ${conflict.file}`); logger.info(`  ${conflict.description}`); break; } } /** Log the update plan details / async function logUpdatePlan(plan: UpdatePlan): Promise<void> { logger.info(`Update Plan: ${plan.fromVersion} â†’ ${plan.toVersion}`); logger.info(`Change Type: ${plan.diff.changeType}`); logger.info(`Breaking: ${plan.diff.breaking ? 'Yes' : 'No'}`); logger.info(`Strategy: ${plan.strategy.type}`); if (plan.diff.files.length > 0) { logger.info('\nFile Changes:'); for (const file of plan.diff.files) { const status = file.status.charAt(0).toUpperCase() + file.status.slice(1); logger.info(`  ${status}: ${file.path} (+${file.insertions}/-${file.deletions})`); } } if (plan.conflicts.length > 0) { logger.warn('\nConflicts:'); for (const conflict of plan.conflicts) { logger.warn(`  ${conflict.file}: ${conflict.description}`); } } if (plan.diff.commits.length > 0) { logger.info('\nCommits:'); for (const commit of plan.diff.commits.slice(0, 5)) { logger.info(`  ${commit.shortHash}: ${commit.message}`); } if (plan.diff.commits.length > 5) { logger.info(`  ... and ${plan.diff.commits.length - 5} more commits`); } } } // Utility functions for version management /** Get the latest tag in the repository / export async function getLatestTag(cwd: string = process.cwd()): Promise<string | null> { try { const result = await execa('git', ['describe', '--tags', '--abbrev=0'], { cwd, silent: true }); return result.stdout.trim() || null; } catch { return null; } } /** Get all tags in the repository, sorted by version

---

## getBranches

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function getBranches(
  cwd: string = process.cwd(),
  includeRemote: boolean = false
): Promise<string[]>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit / export async function commit( options: CommitOptions, cwd: string = process.cwd() ): Promise<string> { const args = ['commit', '-m', options.message]; if (options.amend) { args.push('--amend'); } if (options.signOff) { args.push('--signoff'); } if (options.allowEmpty) { args.push('--allow-empty'); } try { const result = await gitExeca(args, { cwd }); // Extract commit hash from output const match = result.stdout.match(/\[.+ ([a-f0-9]+)\]/); return match ? match[1] : ''; } catch (error) { throw new CLIError(`Failed to create commit`, { code: 'GIT_COMMIT_FAILED', cause: error instanceof Error ? error : undefined, context: { options, cwd }, }); } } /** Get commit history / export async function getCommits( count: number = 10, cwd: string = process.cwd() ): Promise<GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await gitExeca(['log', `-${count}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message, }; }); } catch (error) { throw new CLIError(`Failed to get commits`, { code: 'GIT_LOG_FAILED', cause: error instanceof Error ? error : undefined, context: { count, cwd }, }); } } /** Get basic diff information / export async function getDiff( from?: string, to?: string, cwd: string = process.cwd() ): Promise<string> { const args = ['diff']; if (from) { args.push(from); if (to) { args.push(to); } } try { const result = await gitExeca(args, { cwd }); return result.stdout; } catch (error) { throw new CLIError(`Failed to get diff`, { code: 'GIT_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { from, to, cwd }, }); } } /** Get branches

---

## getChangeType

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none'
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change

---

## getCommits

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function getCommits(
  count: number = 10,
  cwd: string = process.cwd()
): Promise<GitCommit[]>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit / export async function commit( options: CommitOptions, cwd: string = process.cwd() ): Promise<string> { const args = ['commit', '-m', options.message]; if (options.amend) { args.push('--amend'); } if (options.signOff) { args.push('--signoff'); } if (options.allowEmpty) { args.push('--allow-empty'); } try { const result = await gitExeca(args, { cwd }); // Extract commit hash from output const match = result.stdout.match(/\[.+ ([a-f0-9]+)\]/); return match ? match[1] : ''; } catch (error) { throw new CLIError(`Failed to create commit`, { code: 'GIT_COMMIT_FAILED', cause: error instanceof Error ? error : undefined, context: { options, cwd }, }); } } /** Get commit history

---

## getCurrentCommit

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function getCurrentCommit(cwd: string = process.cwd()): Promise<string>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit / export async function commit( options: CommitOptions, cwd: string = process.cwd() ): Promise<string> { const args = ['commit', '-m', options.message]; if (options.amend) { args.push('--amend'); } if (options.signOff) { args.push('--signoff'); } if (options.allowEmpty) { args.push('--allow-empty'); } try { const result = await gitExeca(args, { cwd }); // Extract commit hash from output const match = result.stdout.match(/\[.+ ([a-f0-9]+)\]/); return match ? match[1] : ''; } catch (error) { throw new CLIError(`Failed to create commit`, { code: 'GIT_COMMIT_FAILED', cause: error instanceof Error ? error : undefined, context: { options, cwd }, }); } } /** Get commit history / export async function getCommits( count: number = 10, cwd: string = process.cwd() ): Promise<GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await gitExeca(['log', `-${count}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message, }; }); } catch (error) { throw new CLIError(`Failed to get commits`, { code: 'GIT_LOG_FAILED', cause: error instanceof Error ? error : undefined, context: { count, cwd }, }); } } /** Get basic diff information / export async function getDiff( from?: string, to?: string, cwd: string = process.cwd() ): Promise<string> { const args = ['diff']; if (from) { args.push(from); if (to) { args.push(to); } } try { const result = await gitExeca(args, { cwd }); return result.stdout; } catch (error) { throw new CLIError(`Failed to get diff`, { code: 'GIT_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { from, to, cwd }, }); } } /** Get branches / export async function getBranches( cwd: string = process.cwd(), includeRemote: boolean = false ): Promise<string[]> { const args = ['branch']; if (includeRemote) { args.push('-a'); } try { const result = await gitExeca(args, { cwd }); return result.stdout .trim() .split('\n') .map(line => line.replace(/^\*?\s+/, '').trim()) .filter(line => line && !line.startsWith('->')); } catch (error) { throw new CLIError(`Failed to list branches`, { code: 'GIT_BRANCH_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, includeRemote }, }); } } /** Create a new branch / export async function createBranch( name: string, cwd: string = process.cwd(), checkout: boolean = false ): Promise<void> { const args = checkout ? ['checkout', '-b', name] : ['branch', name]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to create branch`, { code: 'GIT_BRANCH_CREATE_FAILED', cause: error instanceof Error ? error : undefined, context: { name, cwd, checkout }, }); } } /** Checkout a branch or commit / export async function checkout( ref: string, cwd: string = process.cwd() ): Promise<void> { try { await gitExeca(['checkout', ref], { cwd }); } catch (error) { throw new CLIError(`Failed to checkout`, { code: 'GIT_CHECKOUT_FAILED', cause: error instanceof Error ? error : undefined, context: { ref, cwd }, }); } } /** Get the current commit hash

---

## getDiff

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function getDiff(
  from?: string,
  to?: string,
  cwd: string = process.cwd()
): Promise<string>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit / export async function commit( options: CommitOptions, cwd: string = process.cwd() ): Promise<string> { const args = ['commit', '-m', options.message]; if (options.amend) { args.push('--amend'); } if (options.signOff) { args.push('--signoff'); } if (options.allowEmpty) { args.push('--allow-empty'); } try { const result = await gitExeca(args, { cwd }); // Extract commit hash from output const match = result.stdout.match(/\[.+ ([a-f0-9]+)\]/); return match ? match[1] : ''; } catch (error) { throw new CLIError(`Failed to create commit`, { code: 'GIT_COMMIT_FAILED', cause: error instanceof Error ? error : undefined, context: { options, cwd }, }); } } /** Get commit history / export async function getCommits( count: number = 10, cwd: string = process.cwd() ): Promise<GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await gitExeca(['log', `-${count}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message, }; }); } catch (error) { throw new CLIError(`Failed to get commits`, { code: 'GIT_LOG_FAILED', cause: error instanceof Error ? error : undefined, context: { count, cwd }, }); } } /** Get basic diff information

---

## getLatestTag

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export async function getLatestTag(cwd: string = process.cwd()): Promise<string | null>
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation) / export function satisfiesRange(version: SemanticVersion, range: string): boolean { // Basic range patterns: "^1.2.3", "~1.2.3", ">=1.2.3", "1.2.3" if (range.startsWith('^')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('~')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && version.minor === targetVersion.minor && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) > 0; } if (range.startsWith('<=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) <= 0; } if (range.startsWith('<')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) < 0; } // Exact match const targetVersion = parseVersion(range); return compareVersions(version, targetVersion) === 0; } // Git-based version diffing /** Get detailed diff between two git tags/commits / export async function getVersionDiff( fromTag: string, toTag: string, cwd: string = process.cwd() ): Promise<VersionDiff> { const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); try { // Get commit history between versions const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); // Get file changes const files = await getFilesBetweenTags(fromTag, toTag, cwd); // Determine if this is a breaking change const breaking = await isBreakingChange(fromTag, toTag, cwd); return { from: fromVersion, to: toVersion, changeType: getChangeType(fromVersion, toVersion), files, commits, breaking }; } catch (error) { throw new CLIError(`Failed to get version diff from ${fromTag} to ${toTag}`, { code: 'VERSION_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { fromTag, toTag, cwd } }); } } /** Get commits between two git tags / async function getCommitsBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<git.GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await execa('git', ['log', `${fromTag}..${toTag}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message }; }); } catch (error) { throw new CLIError(`Failed to get commits between ${fromTag} and ${toTag}`, { code: 'GIT_COMMITS_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Get detailed file changes between two git tags / async function getFilesBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<FileDiff[]> { try { // Get file stats const statsResult = await execa('git', ['diff', '--numstat', `${fromTag}..${toTag}`], { cwd }); const stats = new Map<string, { insertions: number; deletions: number }>(); for (const line of statsResult.stdout.trim().split('\n').filter(Boolean)) { const [insertions, deletions, path] = line.split('\t'); stats.set(path, { insertions: insertions === '-' ? 0 : parseInt(insertions, 10), deletions: deletions === '-' ? 0 : parseInt(deletions, 10) }); } // Get file status (added, modified, deleted, renamed) const nameStatusResult = await execa('git', ['diff', '--name-status', `${fromTag}..${toTag}`], { cwd }); const files: FileDiff[] = []; for (const line of nameStatusResult.stdout.trim().split('\n').filter(Boolean)) { const parts = line.split('\t'); const status = parts[0]; const path = parts[1]; let fileStatus: FileDiff['status']; let oldPath: string | undefined; if (status === 'A') { fileStatus = 'added'; } else if (status === 'D') { fileStatus = 'deleted'; } else if (status === 'M') { fileStatus = 'modified'; } else if (status.startsWith('R')) { fileStatus = 'renamed'; oldPath = path; // For renames, the new path is in parts[2] const newPath = parts[2]; const fileStats = stats.get(newPath) || { insertions: 0, deletions: 0 }; files.push({ path: newPath, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); continue; } else { fileStatus = 'modified'; // Default for other statuses } const fileStats = stats.get(path) || { insertions: 0, deletions: 0 }; files.push({ path, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); } return files; } catch (error) { throw new CLIError(`Failed to get file changes between ${fromTag} and ${toTag}`, { code: 'GIT_FILES_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Heuristic to determine if changes are breaking / async function isBreakingChange( fromTag: string, toTag: string, cwd: string ): Promise<boolean> { try { // Check commit messages for breaking change indicators const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); const breakingKeywords = [ 'BREAKING CHANGE', 'breaking change', 'BREAKING:', '!:', 'breaking:', 'BC:', 'bc:' ]; const hasBreakingCommit = commits.some(commit => breakingKeywords.some(keyword => commit.message.toLowerCase().includes(keyword.toLowerCase()) ) ); if (hasBreakingCommit) return true; // Check for major version bump const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); return fromVersion.major !== toVersion.major; } catch { // Default to false if we can't determine return false; } } // Update planning and application /** Create an update plan for applying changes / export async function createUpdatePlan( fromVersion: string, toVersion: string, targetDir: string, options: UpdateOptions = {} ): Promise<UpdatePlan> { try { const diff = await getVersionDiff(fromVersion, toVersion, targetDir); const conflicts = await detectConflicts(diff, targetDir); const strategy: UpdateStrategy = { type: options.strategy?.type || 'merge', excludePaths: options.strategy?.excludePaths || [ '.git', 'node_modules', '.env', '.env.local' ], preserveFiles: options.strategy?.preserveFiles || [ 'package.json', 'README.md', '.gitignore' ], customMergers: options.strategy?.customMergers || {} }; return { fromVersion, toVersion, diff, conflicts, strategy, backupRequired: options.createBackup !== false || conflicts.length > 0 }; } catch (error) { throw new CLIError(`Failed to create update plan`, { code: 'UPDATE_PLAN_FAILED', cause: error instanceof Error ? error : undefined, context: { fromVersion, toVersion, targetDir } }); } } /** Detect potential conflicts in the update / async function detectConflicts( diff: VersionDiff, targetDir: string ): Promise<UpdateConflict[]> { const conflicts: UpdateConflict[] = []; for (const file of diff.files) { const filePath = path.join(targetDir, file.path); try { // Check if file exists and has local changes if (await exists(filePath)) { if (file.status === 'deleted') { conflicts.push({ file: file.path, type: 'deletion', description: `File exists locally but is deleted in the update`, resolution: 'manual' }); } else if (file.status === 'modified') { // Could check git status here to see if file has local changes const hasLocalChanges = await checkLocalChanges(filePath, targetDir); if (hasLocalChanges) { conflicts.push({ file: file.path, type: 'content', description: `File has both local and remote changes`, resolution: 'merge' }); } } } // Check file permissions const stats = await fs.stat(filePath).catch(() => null); if (stats && !stats.isFile()) { conflicts.push({ file: file.path, type: 'permission', description: `Path exists but is not a regular file`, resolution: 'skip' }); } } catch { // File doesn't exist - no conflict } } return conflicts; } /** Check if a file has local changes (not committed) / async function checkLocalChanges(filePath: string, cwd: string): Promise<boolean> { try { const relativePath = path.relative(cwd, filePath); const result = await execa('git', ['status', '--porcelain', relativePath], { cwd }); return result.stdout.trim().length > 0; } catch { return false; } } /** Apply an update plan / export async function applyUpdate( plan: UpdatePlan, targetDir: string, options: UpdateOptions = {} ): Promise<void> { if (options.dryRun) { logger.info('Dry run mode - no changes will be applied'); await logUpdatePlan(plan); return; } try { // Create backup if required if (plan.backupRequired && options.createBackup !== false) { await createBackup(targetDir); } // Apply changes based on strategy switch (plan.strategy.type) { case 'overwrite': await applyOverwriteStrategy(plan, targetDir, options); break; case 'merge': await applyMergeStrategy(plan, targetDir, options); break; case 'selective': await applySelectiveStrategy(plan, targetDir, options); break; } logger.success(`Successfully updated from ${plan.fromVersion} to ${plan.toVersion}`); } catch (error) { throw new CLIError(`Failed to apply update`, { code: 'UPDATE_APPLICATION_FAILED', cause: error instanceof Error ? error : undefined, context: { plan, targetDir, options } }); } } /** Create a backup of the target directory / async function createBackup(targetDir: string): Promise<string> { const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); const backupDir = `${targetDir}.backup.${timestamp}`; logger.info(`Creating backup at ${backupDir}`); try { await execa('cp', ['-r', targetDir, backupDir]); return backupDir; } catch { // Fallback for systems without cp await copyDirectory(targetDir, backupDir); return backupDir; } } /** Recursive directory copy fallback / async function copyDirectory(src: string, dest: string): Promise<void> { await ensureDir(dest); const items = await fs.readdir(src); for (const item of items) { const srcPath = path.join(src, item); const destPath = path.join(dest, item); const stats = await fs.stat(srcPath); if (stats.isDirectory()) { await copyDirectory(srcPath, destPath); } else { await copyFile(srcPath, destPath); } } } /** Apply overwrite strategy (replace everything) / async function applyOverwriteStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying overwrite strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } else if (file.status === 'added' || file.status === 'modified') { // This would require the source content - placeholder for now logger.info(`Would update: ${file.path}`); } } } /** Apply merge strategy (intelligent merging) / async function applyMergeStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying merge strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); // Handle conflicts based on their resolution strategy const conflict = plan.conflicts.find(c => c.file === file.path); if (conflict) { await handleConflict(conflict, targetPath, plan.strategy); } else { // No conflict - apply change directly if (file.status === 'added' || file.status === 'modified') { logger.info(`Would update: ${file.path}`); } else if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } } } } /** Apply selective strategy (user chooses what to update) / async function applySelectiveStrategy( _plan: UpdatePlan, _targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying selective strategy'); // Implementation would involve prompting user for each file change // This is a placeholder for the selective update logic logger.info('Selective strategy not yet fully implemented'); } /** Handle update conflicts / async function handleConflict( conflict: UpdateConflict, _targetPath: string, _strategy: UpdateStrategy ): Promise<void> { switch (conflict.resolution) { case 'skip': logger.warn(`Skipping conflicted file: ${conflict.file}`); break; case 'overwrite': logger.warn(`Overwriting conflicted file: ${conflict.file}`); // Implementation would overwrite the file break; case 'merge': logger.info(`Attempting to merge conflicted file: ${conflict.file}`); // Implementation would use git merge or custom merger break; case 'manual': logger.error(`Manual resolution required for: ${conflict.file}`); logger.info(`  ${conflict.description}`); break; } } /** Log the update plan details / async function logUpdatePlan(plan: UpdatePlan): Promise<void> { logger.info(`Update Plan: ${plan.fromVersion} â†’ ${plan.toVersion}`); logger.info(`Change Type: ${plan.diff.changeType}`); logger.info(`Breaking: ${plan.diff.breaking ? 'Yes' : 'No'}`); logger.info(`Strategy: ${plan.strategy.type}`); if (plan.diff.files.length > 0) { logger.info('\nFile Changes:'); for (const file of plan.diff.files) { const status = file.status.charAt(0).toUpperCase() + file.status.slice(1); logger.info(`  ${status}: ${file.path} (+${file.insertions}/-${file.deletions})`); } } if (plan.conflicts.length > 0) { logger.warn('\nConflicts:'); for (const conflict of plan.conflicts) { logger.warn(`  ${conflict.file}: ${conflict.description}`); } } if (plan.diff.commits.length > 0) { logger.info('\nCommits:'); for (const commit of plan.diff.commits.slice(0, 5)) { logger.info(`  ${commit.shortHash}: ${commit.message}`); } if (plan.diff.commits.length > 5) { logger.info(`  ... and ${plan.diff.commits.length - 5} more commits`); } } } // Utility functions for version management /** Get the latest tag in the repository

---

## getRepositoryRoot

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory

---

## getStatus

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status

---

## getVersionDiff

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export async function getVersionDiff(
  fromTag: string, 
  toTag: string, 
  cwd: string = process.cwd()
): Promise<VersionDiff>
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation) / export function satisfiesRange(version: SemanticVersion, range: string): boolean { // Basic range patterns: "^1.2.3", "~1.2.3", ">=1.2.3", "1.2.3" if (range.startsWith('^')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('~')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && version.minor === targetVersion.minor && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) > 0; } if (range.startsWith('<=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) <= 0; } if (range.startsWith('<')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) < 0; } // Exact match const targetVersion = parseVersion(range); return compareVersions(version, targetVersion) === 0; } // Git-based version diffing /** Get detailed diff between two git tags/commits

---

## getWorkspaceSummary

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export function getWorkspaceSummary(workspace: WorkspaceConfiguration):
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace / export async function discoverPackages( cwd: string = process.cwd(), workspaceType?: WorkspaceType ): Promise<WorkspacePackage[]> { const type = workspaceType || await detectWorkspaceType(cwd); const packages: WorkspacePackage[] = []; try { let packagePaths: string[] = []; switch (type) { case 'nx': packagePaths = await discoverNxPackages(cwd); break; case 'lerna': packagePaths = await discoverLernaPackages(cwd); break; case 'rush': packagePaths = await discoverRushPackages(cwd); break; case 'pnpm-workspace': case 'yarn-workspace': case 'npm-workspace': packagePaths = await discoverWorkspacesPackages(cwd); break; case 'turbo': // Turbo usually relies on other workspace configurations packagePaths = await discoverWorkspacesPackages(cwd); break; case 'multi-tool': // Try multiple discovery methods packagePaths = await discoverMultiToolPackages(cwd); break; case 'single-package': packagePaths = [cwd]; break; } // Process each discovered package for (const packagePath of packagePaths) { try { const pkg = await loadPackage(packagePath, cwd); if (pkg) { packages.push(pkg); } } catch (error) { workspaceLogger.warn(`Failed to load package at ${packagePath}: ${error}`); } } return packages; } catch (error) { throw new CLIError(`Failed to discover packages in workspace`, { code: 'WORKSPACE_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, workspaceType: type } }); } } /** Load a single package from a directory / async function loadPackage( packagePath: string, workspaceRoot: string ): Promise<WorkspacePackage | null> { const packageJsonPath = path.join(packagePath, 'package.json'); if (!await exists(packageJsonPath)) { return null; } try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (!packageJson.name) { workspaceLogger.warn(`Package at ${packagePath} has no name field`); return null; } const dependencies = new Map(Object.entries(packageJson.dependencies || {})); const devDependencies = new Map(Object.entries(packageJson.devDependencies || {})); const peerDependencies = new Map(Object.entries(packageJson.peerDependencies || {})); const scripts = new Map(Object.entries(packageJson.scripts || {})); return { name: packageJson.name, version: packageJson.version || '0.0.0', path: packagePath, relativePath: path.relative(workspaceRoot, packagePath), packageJson, dependencies, devDependencies, peerDependencies, scripts, isPrivate: packageJson.private || false, workspaceDependencies: [] // Will be populated later }; } catch (error) { throw new CLIError(`Failed to parse package.json at ${packagePath}`, { code: 'PACKAGE_JSON_PARSE_FAILED', cause: error instanceof Error ? error : undefined, context: { packagePath } }); } } // Package discovery methods for different workspace types async function discoverNxPackages(cwd: string): Promise<string[]> { const paths: string[] = []; try { // Try nx.json first const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { const nxConfig: NxConfiguration = JSON.parse(await readFile(nxJsonPath)); if (nxConfig.projects) { for (const [, projectConfig] of Object.entries(nxConfig.projects)) { if (typeof projectConfig === 'string') { paths.push(path.join(cwd, projectConfig)); } else if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, projectConfig.root as string)); } } } } // Try workspace.json as fallback const workspaceJsonPath = path.join(cwd, 'workspace.json'); if (paths.length === 0 && await exists(workspaceJsonPath)) { const workspaceConfig = JSON.parse(await readFile(workspaceJsonPath)); if (workspaceConfig.projects) { for (const [, projectConfig] of Object.entries(workspaceConfig.projects)) { if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, (projectConfig as any).root)); } } } } // If no explicit projects, scan common patterns if (paths.length === 0) { const patterns = ['apps/*', 'libs/*', 'packages/*', 'projects/*']; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } } return paths; } catch (error) { throw new CLIError('Failed to discover Nx packages', { code: 'NX_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverLernaPackages(cwd: string): Promise<string[]> { try { const lernaJsonPath = path.join(cwd, 'lerna.json'); const lernaConfig: LernaConfiguration = JSON.parse(await readFile(lernaJsonPath)); const patterns = lernaConfig.packages || ['packages/*']; const paths: string[] = []; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover Lerna packages', { code: 'LERNA_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverRushPackages(cwd: string): Promise<string[]> { try { const rushJsonPath = path.join(cwd, 'rush.json'); const rushConfig: RushConfiguration = JSON.parse(await readFile(rushJsonPath)); return rushConfig.projects.map(project => path.join(cwd, project.projectFolder) ); } catch (error) { throw new CLIError('Failed to discover Rush packages', { code: 'RUSH_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverWorkspacesPackages(cwd: string): Promise<string[]> { try { const packageJsonPath = path.join(cwd, 'package.json'); const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); let workspacePatterns: string[] = []; if (packageJson.workspaces) { if (Array.isArray(packageJson.workspaces)) { workspacePatterns = packageJson.workspaces; } else if (packageJson.workspaces.packages) { workspacePatterns = packageJson.workspaces.packages; } } // Check pnpm-workspace.yaml const pnpmWorkspacePath = path.join(cwd, 'pnpm-workspace.yaml'); if (workspacePatterns.length === 0 && await exists(pnpmWorkspacePath)) { try { // Simple YAML parsing for packages field const yamlContent = await readFile(pnpmWorkspacePath); const packagesMatch = yamlContent.match(/packages:\s*\n((?:\s*-\s*.+\n?)*)/); if (packagesMatch) { workspacePatterns = packagesMatch[1] .split('\n') .map(line => line.trim().replace(/^-\s*/, '').replace(/['"](.+)['"]/, '$1')) .filter(Boolean); } } catch (error) { workspaceLogger.warn(`Failed to parse pnpm-workspace.yaml: ${error}`); } } if (workspacePatterns.length === 0) { // Default patterns if none specified workspacePatterns = ['packages/*']; } const paths: string[] = []; for (const pattern of workspacePatterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover workspace packages', { code: 'WORKSPACES_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverMultiToolPackages(cwd: string): Promise<string[]> { const allPaths: Set<string> = new Set(); // Try all discovery methods and combine results const discoveryMethods = [ () => discoverNxPackages(cwd), () => discoverLernaPackages(cwd), () => discoverWorkspacesPackages(cwd), () => discoverRushPackages(cwd) ]; for (const method of discoveryMethods) { try { const paths = await method(); paths.forEach(p => allPaths.add(p)); } catch { // Ignore errors from individual discovery methods } } return Array.from(allPaths); } /** Load complete workspace configuration / export async function loadWorkspace(cwd: string = process.cwd()): Promise<WorkspaceConfiguration> { try { const workspaceType = await detectWorkspaceType(cwd); const packageManager = await detectPackageManager(cwd); const packages = await discoverPackages(cwd, workspaceType); const tools = await loadWorkspaceTools(cwd); // Create package map for quick lookups const packageMap = new Map<string, WorkspacePackage>(); packages.forEach(pkg => packageMap.set(pkg.name, pkg)); // Build dependency graph const dependencyGraph = buildDependencyGraph(packages); // Load workspace-level scripts const scripts = await loadWorkspaceScripts(cwd); return { type: workspaceType, root: cwd, packages, packageMap, dependencyGraph, tools, packageManager, scripts }; } catch (error) { throw new CLIError(`Failed to load workspace configuration`, { code: 'WORKSPACE_LOAD_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } /** Load workspace tools configuration / async function loadWorkspaceTools(cwd: string): Promise<WorkspaceTools> { const tools: WorkspaceTools = { hasNx: false, hasLerna: false, hasRush: false, hasTurbo: false, hasWorkspaces: false, configurations: {} }; // Check for Nx const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { tools.hasNx = true; try { tools.configurations.nx = JSON.parse(await readFile(nxJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse nx.json: ${error}`); } } // Check for Lerna const lernaJsonPath = path.join(cwd, 'lerna.json'); if (await exists(lernaJsonPath)) { tools.hasLerna = true; try { tools.configurations.lerna = JSON.parse(await readFile(lernaJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse lerna.json: ${error}`); } } // Check for Rush const rushJsonPath = path.join(cwd, 'rush.json'); if (await exists(rushJsonPath)) { tools.hasRush = true; try { tools.configurations.rush = JSON.parse(await readFile(rushJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse rush.json: ${error}`); } } // Check for Turbo const turboJsonPath = path.join(cwd, 'turbo.json'); if (await exists(turboJsonPath)) { tools.hasTurbo = true; try { tools.configurations.turbo = JSON.parse(await readFile(turboJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse turbo.json: ${error}`); } } // Check for workspaces const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { tools.hasWorkspaces = true; if (Array.isArray(packageJson.workspaces)) { tools.configurations.workspaces = { packages: packageJson.workspaces }; } else if (packageJson.workspaces.packages) { tools.configurations.workspaces = packageJson.workspaces; } } } catch (error) { workspaceLogger.warn(`Failed to parse package.json: ${error}`); } } return tools; } /** Load workspace-level scripts / async function loadWorkspaceScripts(cwd: string): Promise<Map<string, string>> { const scripts = new Map<string, string>(); try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.scripts) { Object.entries(packageJson.scripts).forEach(([name, script]) => { scripts.set(name, script); }); } } } catch (error) { workspaceLogger.warn(`Failed to load workspace scripts: ${error}`); } return scripts; } /** Build dependency graph for workspace packages / function buildDependencyGraph(packages: WorkspacePackage[]): DependencyGraph { const nodes = new Map<string, DependencyNode>(); const edges: DependencyEdge[] = []; const packageNames = new Set(packages.map(pkg => pkg.name)); // Initialize nodes packages.forEach(pkg => { nodes.set(pkg.name, { name: pkg.name, package: pkg, dependencies: new Set(), dependents: new Set(), depth: 0 }); }); // Build edges and populate workspace dependencies packages.forEach(pkg => { const node = nodes.get(pkg.name)!; // Process dependencies ['dependencies', 'devDependencies', 'peerDependencies'].forEach(depType => { const deps = pkg[depType as keyof WorkspacePackage] as Map<string, string> | undefined; if (!deps) return; deps.forEach((_, depName) => { if (packageNames.has(depName)) { // This is a workspace dependency pkg.workspaceDependencies.push(depName); node.dependencies.add(depName); const targetNode = nodes.get(depName); if (targetNode) { targetNode.dependents.add(pkg.name); } edges.push({ from: pkg.name, to: depName, type: depType as 'dependencies' | 'devDependencies' | 'peerDependencies' }); } }); }); }); // Calculate depths (topological sort) const topologicalOrder = topologicalSort(nodes); // Detect circular dependencies const circularDependencies = detectCircularDependencies(nodes); return { nodes, edges, topologicalOrder, circularDependencies }; } /** Perform topological sort on dependency graph / function topologicalSort(nodes: Map<string, DependencyNode>): string[] { const visited = new Set<string>(); const temp = new Set<string>(); const result: string[] = []; function visit(nodeName: string): void { if (temp.has(nodeName)) return; // Circular dependency if (visited.has(nodeName)) return; temp.add(nodeName); const node = nodes.get(nodeName); if (node) { node.dependencies.forEach(depName => visit(depName)); node.depth = Math.max(node.depth, ...Array.from(node.dependencies).map(dep => (nodes.get(dep)?.depth || 0) + 1 )); } temp.delete(nodeName); visited.add(nodeName); result.push(nodeName); } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { visit(nodeName); } }); return result; } /** Detect circular dependencies in the graph / function detectCircularDependencies(nodes: Map<string, DependencyNode>): string[][] { const visited = new Set<string>(); const recursionStack = new Set<string>(); const cycles: string[][] = []; const currentPath: string[] = []; function dfs(nodeName: string): boolean { visited.add(nodeName); recursionStack.add(nodeName); currentPath.push(nodeName); const node = nodes.get(nodeName); if (node) { for (const depName of node.dependencies) { if (!visited.has(depName)) { if (dfs(depName)) return true; } else if (recursionStack.has(depName)) { // Found a cycle const cycleStart = currentPath.indexOf(depName); cycles.push(currentPath.slice(cycleStart).concat([depName])); return true; } } } currentPath.pop(); recursionStack.delete(nodeName); return false; } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { dfs(nodeName); } }); return cycles; } // Batch operations and utility functions /** Filter packages based on criteria / export function filterPackages( packages: WorkspacePackage[], filter: PackageFilter ): WorkspacePackage[] { return packages.filter(pkg => { if (filter.names && !filter.names.includes(pkg.name)) return false; if (filter.paths && !filter.paths.some(p => pkg.relativePath.includes(p))) return false; if (filter.hasScript && !pkg.scripts.has(filter.hasScript)) return false; if (filter.hasDependency) { const hasDep = pkg.dependencies.has(filter.hasDependency) || pkg.devDependencies.has(filter.hasDependency) || pkg.peerDependencies.has(filter.hasDependency); if (!hasDep) return false; } if (filter.isPrivate !== undefined && pkg.isPrivate !== filter.isPrivate) return false; if (filter.custom && !filter.custom(pkg)) return false; return true; }); } /** Run a script across multiple packages / export async function runScript( packages: WorkspacePackage[], scriptName: string, options: BatchOperationOptions = {} ): Promise<Map<string, { success: boolean; output?: string; error?: Error }>> { const { concurrency = 4, continueOnError = false, filter, scope, ignore = [], onProgress, onPackageComplete, onPackageError } = options; const results = new Map<string, { success: boolean; output?: string; error?: Error }>(); let filteredPackages = packages; // Apply filters if (filter) { filteredPackages = filterPackages(filteredPackages, filter); } if (scope) { filteredPackages = filteredPackages.filter(pkg => scope.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } if (ignore.length > 0) { filteredPackages = filteredPackages.filter(pkg => !ignore.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } // Filter packages that have the script const packagesWithScript = filteredPackages.filter(pkg => pkg.scripts.has(scriptName)); if (packagesWithScript.length === 0) { workspaceLogger.warn(`No packages found with script "${scriptName}"`); return results; } // Import execa here to avoid circular dependencies const { execa } = await import('../core/execution/execa.js'); let completed = 0; const total = packagesWithScript.length; const runPackageScript = async (pkg: WorkspacePackage): Promise<void> => { try { // Get the script command (we know it exists from the filter) pkg.scripts.get(scriptName)!; const result = await execa('npm', ['run', scriptName], { cwd: pkg.path, silent: true }); results.set(pkg.name, { success: true, output: result.stdout }); onPackageComplete?.(pkg, result); } catch (error) { const err = error instanceof Error ? error : new Error(String(error)); results.set(pkg.name, { success: false, error: err }); onPackageError?.(pkg, err); if (!continueOnError) { throw err; } } finally { completed++; onProgress?.(completed, total, pkg.name); } }; // Execute with concurrency limit const semaphore = Array(concurrency).fill(null); const packageQueue = [...packagesWithScript]; await Promise.all( semaphore.map(async () => { while (packageQueue.length > 0) { const pkg = packageQueue.shift(); if (pkg) { await runPackageScript(pkg); } } }) ); return results; } /** Install dependencies for packages / export async function installDependencies( packages: WorkspacePackage[], packageManager: PackageManager = 'npm', options: BatchOperationOptions = {} ): Promise<Map<string, { success: boolean; output?: string; error?: Error }>> { const { execa } = await import('../core/execution/execa.js'); const results = new Map<string, { success: boolean; output?: string; error?: Error }>(); let filteredPackages = packages; if (options.filter) { filteredPackages = filterPackages(filteredPackages, options.filter); } const commands: Record<PackageManager, string[]> = { npm: ['npm', 'install'], yarn: ['yarn', 'install'], pnpm: ['pnpm', 'install'], bun: ['bun', 'install'], rush: ['rush', 'install'], auto: ['npm', 'install'] // fallback }; const [cmd, ...args] = commands[packageManager]; let completed = 0; const total = filteredPackages.length; for (const pkg of filteredPackages) { try { const result = await execa(cmd, args, { cwd: pkg.path, silent: true }); results.set(pkg.name, { success: true, output: result.stdout }); options.onPackageComplete?.(pkg, result); } catch (error) { const err = error instanceof Error ? error : new Error(String(error)); results.set(pkg.name, { success: false, error: err }); options.onPackageError?.(pkg, err); if (!options.continueOnError) { throw err; } } finally { completed++; options.onProgress?.(completed, total, pkg.name); } } return results; } /** Get packages affected by changes since a specific commit/branch / export async function getAffectedPackages( workspace: WorkspaceConfiguration, options: ChangeDetectionOptions = {} ): Promise<WorkspacePackage[]> { const { since = 'HEAD~1', includeUncommitted = true, includeDependents = true, maxDepth = Infinity } = options; const { execa } = await import('../core/execution/execa.js'); const affectedPackages = new Set<string>(); try { // Get list of changed files const changedFiles = new Set<string>(); // Get committed changes try { const gitDiffResult = await execa('git', ['diff', '--name-only', since], { cwd: workspace.root, silent: true }); gitDiffResult.stdout.trim().split('\n').filter(Boolean).forEach(file => changedFiles.add(file) ); } catch (error) { workspaceLogger.warn(`Failed to get git diff: ${error}`); } // Get uncommitted changes if requested if (includeUncommitted) { try { const statusResult = await execa('git', ['status', '--porcelain'], { cwd: workspace.root, silent: true }); statusResult.stdout.trim().split('\n').filter(Boolean).forEach(line => { const file = line.substring(3); // Remove status prefix changedFiles.add(file); }); } catch (error) { workspaceLogger.warn(`Failed to get git status: ${error}`); } } // Find packages containing changed files for (const file of changedFiles) { for (const pkg of workspace.packages) { const relativePath = pkg.relativePath || path.relative(workspace.root, pkg.path); if (file.startsWith(relativePath + '/') || file === relativePath) { affectedPackages.add(pkg.name); break; } } } // Include dependents if requested if (includeDependents && affectedPackages.size > 0) { const dependentsToAdd = new Set<string>(); let currentDepth = 0; let currentLevel = new Set(affectedPackages); while (currentLevel.size > 0 && currentDepth < maxDepth) { const nextLevel = new Set<string>(); for (const pkgName of currentLevel) { const node = workspace.dependencyGraph.nodes.get(pkgName); if (node) { node.dependents.forEach(dependent => { if (!affectedPackages.has(dependent) && !dependentsToAdd.has(dependent)) { dependentsToAdd.add(dependent); nextLevel.add(dependent); } }); } } dependentsToAdd.forEach(dep => affectedPackages.add(dep)); currentLevel = nextLevel; currentDepth++; } } } catch (error) { throw new CLIError('Failed to detect affected packages', { code: 'AFFECTED_DETECTION_FAILED', cause: error instanceof Error ? error : undefined, context: { options } }); } return workspace.packages.filter(pkg => affectedPackages.has(pkg.name)); } /** Validate workspace configuration and packages / export async function validateWorkspace( workspace: WorkspaceConfiguration ): Promise<{ valid: boolean; errors: string[]; warnings: string[] }> { const errors: string[] = []; const warnings: string[] = []; // Check for circular dependencies if (workspace.dependencyGraph.circularDependencies.length > 0) { workspace.dependencyGraph.circularDependencies.forEach((cycle) => { errors.push(`Circular dependency detected: ${cycle.join(' â†’ ')}`); }); } // Check for missing workspace dependencies workspace.packages.forEach(pkg => { pkg.workspaceDependencies.forEach(depName => { if (!workspace.packageMap.has(depName)) { errors.push(`Package "${pkg.name}" depends on workspace package "${depName}" which doesn't exist`); } }); }); // Check for duplicate package names const packageNames = new Map<string, string[]>(); workspace.packages.forEach(pkg => { if (!packageNames.has(pkg.name)) { packageNames.set(pkg.name, []); } packageNames.get(pkg.name)!.push(pkg.relativePath); }); packageNames.forEach((paths, name) => { if (paths.length > 1) { errors.push(`Duplicate package name "${name}" found in: ${paths.join(', ')}`); } }); // Check for inconsistent versions of workspace dependencies const dependencyVersions = new Map<string, Map<string, string[]>>(); workspace.packages.forEach(pkg => { // Check all dependencies that are also workspace packages ['dependencies', 'devDependencies', 'peerDependencies'].forEach(depType => { const deps = pkg[depType as keyof WorkspacePackage] as Map<string, string> | undefined; if (!deps) return; deps.forEach((version, depName) => { // Only check if this is a workspace package if (workspace.packageMap.has(depName)) { if (!dependencyVersions.has(depName)) { dependencyVersions.set(depName, new Map()); } const versionMap = dependencyVersions.get(depName)!; if (!versionMap.has(version)) { versionMap.set(version, []); } versionMap.get(version)!.push(pkg.name); } }); }); }); dependencyVersions.forEach((versionMap, depName) => { if (versionMap.size > 1) { const versions = Array.from(versionMap.entries()).map(([version, packages]) => `${version} (used by: ${packages.join(', ')})` ); warnings.push(`Inconsistent versions for workspace dependency "${depName}": ${versions.join('; ')}`); } }); return { valid: errors.length === 0, errors, warnings }; } /** Get workspace summary information

---

## GitCommit

**Type**: `interface`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

---

## GitStatus

**Type**: `interface`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

---

## init

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function init(
  directory: string = process.cwd(),
  options:
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository

---

## installDependencies

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function installDependencies(
  packages: WorkspacePackage[],
  packageManager: PackageManager = 'npm',
  options: BatchOperationOptions =
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace / export async function discoverPackages( cwd: string = process.cwd(), workspaceType?: WorkspaceType ): Promise<WorkspacePackage[]> { const type = workspaceType || await detectWorkspaceType(cwd); const packages: WorkspacePackage[] = []; try { let packagePaths: string[] = []; switch (type) { case 'nx': packagePaths = await discoverNxPackages(cwd); break; case 'lerna': packagePaths = await discoverLernaPackages(cwd); break; case 'rush': packagePaths = await discoverRushPackages(cwd); break; case 'pnpm-workspace': case 'yarn-workspace': case 'npm-workspace': packagePaths = await discoverWorkspacesPackages(cwd); break; case 'turbo': // Turbo usually relies on other workspace configurations packagePaths = await discoverWorkspacesPackages(cwd); break; case 'multi-tool': // Try multiple discovery methods packagePaths = await discoverMultiToolPackages(cwd); break; case 'single-package': packagePaths = [cwd]; break; } // Process each discovered package for (const packagePath of packagePaths) { try { const pkg = await loadPackage(packagePath, cwd); if (pkg) { packages.push(pkg); } } catch (error) { workspaceLogger.warn(`Failed to load package at ${packagePath}: ${error}`); } } return packages; } catch (error) { throw new CLIError(`Failed to discover packages in workspace`, { code: 'WORKSPACE_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, workspaceType: type } }); } } /** Load a single package from a directory / async function loadPackage( packagePath: string, workspaceRoot: string ): Promise<WorkspacePackage | null> { const packageJsonPath = path.join(packagePath, 'package.json'); if (!await exists(packageJsonPath)) { return null; } try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (!packageJson.name) { workspaceLogger.warn(`Package at ${packagePath} has no name field`); return null; } const dependencies = new Map(Object.entries(packageJson.dependencies || {})); const devDependencies = new Map(Object.entries(packageJson.devDependencies || {})); const peerDependencies = new Map(Object.entries(packageJson.peerDependencies || {})); const scripts = new Map(Object.entries(packageJson.scripts || {})); return { name: packageJson.name, version: packageJson.version || '0.0.0', path: packagePath, relativePath: path.relative(workspaceRoot, packagePath), packageJson, dependencies, devDependencies, peerDependencies, scripts, isPrivate: packageJson.private || false, workspaceDependencies: [] // Will be populated later }; } catch (error) { throw new CLIError(`Failed to parse package.json at ${packagePath}`, { code: 'PACKAGE_JSON_PARSE_FAILED', cause: error instanceof Error ? error : undefined, context: { packagePath } }); } } // Package discovery methods for different workspace types async function discoverNxPackages(cwd: string): Promise<string[]> { const paths: string[] = []; try { // Try nx.json first const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { const nxConfig: NxConfiguration = JSON.parse(await readFile(nxJsonPath)); if (nxConfig.projects) { for (const [, projectConfig] of Object.entries(nxConfig.projects)) { if (typeof projectConfig === 'string') { paths.push(path.join(cwd, projectConfig)); } else if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, projectConfig.root as string)); } } } } // Try workspace.json as fallback const workspaceJsonPath = path.join(cwd, 'workspace.json'); if (paths.length === 0 && await exists(workspaceJsonPath)) { const workspaceConfig = JSON.parse(await readFile(workspaceJsonPath)); if (workspaceConfig.projects) { for (const [, projectConfig] of Object.entries(workspaceConfig.projects)) { if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, (projectConfig as any).root)); } } } } // If no explicit projects, scan common patterns if (paths.length === 0) { const patterns = ['apps/*', 'libs/*', 'packages/*', 'projects/*']; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } } return paths; } catch (error) { throw new CLIError('Failed to discover Nx packages', { code: 'NX_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverLernaPackages(cwd: string): Promise<string[]> { try { const lernaJsonPath = path.join(cwd, 'lerna.json'); const lernaConfig: LernaConfiguration = JSON.parse(await readFile(lernaJsonPath)); const patterns = lernaConfig.packages || ['packages/*']; const paths: string[] = []; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover Lerna packages', { code: 'LERNA_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverRushPackages(cwd: string): Promise<string[]> { try { const rushJsonPath = path.join(cwd, 'rush.json'); const rushConfig: RushConfiguration = JSON.parse(await readFile(rushJsonPath)); return rushConfig.projects.map(project => path.join(cwd, project.projectFolder) ); } catch (error) { throw new CLIError('Failed to discover Rush packages', { code: 'RUSH_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverWorkspacesPackages(cwd: string): Promise<string[]> { try { const packageJsonPath = path.join(cwd, 'package.json'); const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); let workspacePatterns: string[] = []; if (packageJson.workspaces) { if (Array.isArray(packageJson.workspaces)) { workspacePatterns = packageJson.workspaces; } else if (packageJson.workspaces.packages) { workspacePatterns = packageJson.workspaces.packages; } } // Check pnpm-workspace.yaml const pnpmWorkspacePath = path.join(cwd, 'pnpm-workspace.yaml'); if (workspacePatterns.length === 0 && await exists(pnpmWorkspacePath)) { try { // Simple YAML parsing for packages field const yamlContent = await readFile(pnpmWorkspacePath); const packagesMatch = yamlContent.match(/packages:\s*\n((?:\s*-\s*.+\n?)*)/); if (packagesMatch) { workspacePatterns = packagesMatch[1] .split('\n') .map(line => line.trim().replace(/^-\s*/, '').replace(/['"](.+)['"]/, '$1')) .filter(Boolean); } } catch (error) { workspaceLogger.warn(`Failed to parse pnpm-workspace.yaml: ${error}`); } } if (workspacePatterns.length === 0) { // Default patterns if none specified workspacePatterns = ['packages/*']; } const paths: string[] = []; for (const pattern of workspacePatterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover workspace packages', { code: 'WORKSPACES_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverMultiToolPackages(cwd: string): Promise<string[]> { const allPaths: Set<string> = new Set(); // Try all discovery methods and combine results const discoveryMethods = [ () => discoverNxPackages(cwd), () => discoverLernaPackages(cwd), () => discoverWorkspacesPackages(cwd), () => discoverRushPackages(cwd) ]; for (const method of discoveryMethods) { try { const paths = await method(); paths.forEach(p => allPaths.add(p)); } catch { // Ignore errors from individual discovery methods } } return Array.from(allPaths); } /** Load complete workspace configuration / export async function loadWorkspace(cwd: string = process.cwd()): Promise<WorkspaceConfiguration> { try { const workspaceType = await detectWorkspaceType(cwd); const packageManager = await detectPackageManager(cwd); const packages = await discoverPackages(cwd, workspaceType); const tools = await loadWorkspaceTools(cwd); // Create package map for quick lookups const packageMap = new Map<string, WorkspacePackage>(); packages.forEach(pkg => packageMap.set(pkg.name, pkg)); // Build dependency graph const dependencyGraph = buildDependencyGraph(packages); // Load workspace-level scripts const scripts = await loadWorkspaceScripts(cwd); return { type: workspaceType, root: cwd, packages, packageMap, dependencyGraph, tools, packageManager, scripts }; } catch (error) { throw new CLIError(`Failed to load workspace configuration`, { code: 'WORKSPACE_LOAD_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } /** Load workspace tools configuration / async function loadWorkspaceTools(cwd: string): Promise<WorkspaceTools> { const tools: WorkspaceTools = { hasNx: false, hasLerna: false, hasRush: false, hasTurbo: false, hasWorkspaces: false, configurations: {} }; // Check for Nx const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { tools.hasNx = true; try { tools.configurations.nx = JSON.parse(await readFile(nxJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse nx.json: ${error}`); } } // Check for Lerna const lernaJsonPath = path.join(cwd, 'lerna.json'); if (await exists(lernaJsonPath)) { tools.hasLerna = true; try { tools.configurations.lerna = JSON.parse(await readFile(lernaJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse lerna.json: ${error}`); } } // Check for Rush const rushJsonPath = path.join(cwd, 'rush.json'); if (await exists(rushJsonPath)) { tools.hasRush = true; try { tools.configurations.rush = JSON.parse(await readFile(rushJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse rush.json: ${error}`); } } // Check for Turbo const turboJsonPath = path.join(cwd, 'turbo.json'); if (await exists(turboJsonPath)) { tools.hasTurbo = true; try { tools.configurations.turbo = JSON.parse(await readFile(turboJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse turbo.json: ${error}`); } } // Check for workspaces const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { tools.hasWorkspaces = true; if (Array.isArray(packageJson.workspaces)) { tools.configurations.workspaces = { packages: packageJson.workspaces }; } else if (packageJson.workspaces.packages) { tools.configurations.workspaces = packageJson.workspaces; } } } catch (error) { workspaceLogger.warn(`Failed to parse package.json: ${error}`); } } return tools; } /** Load workspace-level scripts / async function loadWorkspaceScripts(cwd: string): Promise<Map<string, string>> { const scripts = new Map<string, string>(); try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.scripts) { Object.entries(packageJson.scripts).forEach(([name, script]) => { scripts.set(name, script); }); } } } catch (error) { workspaceLogger.warn(`Failed to load workspace scripts: ${error}`); } return scripts; } /** Build dependency graph for workspace packages / function buildDependencyGraph(packages: WorkspacePackage[]): DependencyGraph { const nodes = new Map<string, DependencyNode>(); const edges: DependencyEdge[] = []; const packageNames = new Set(packages.map(pkg => pkg.name)); // Initialize nodes packages.forEach(pkg => { nodes.set(pkg.name, { name: pkg.name, package: pkg, dependencies: new Set(), dependents: new Set(), depth: 0 }); }); // Build edges and populate workspace dependencies packages.forEach(pkg => { const node = nodes.get(pkg.name)!; // Process dependencies ['dependencies', 'devDependencies', 'peerDependencies'].forEach(depType => { const deps = pkg[depType as keyof WorkspacePackage] as Map<string, string> | undefined; if (!deps) return; deps.forEach((_, depName) => { if (packageNames.has(depName)) { // This is a workspace dependency pkg.workspaceDependencies.push(depName); node.dependencies.add(depName); const targetNode = nodes.get(depName); if (targetNode) { targetNode.dependents.add(pkg.name); } edges.push({ from: pkg.name, to: depName, type: depType as 'dependencies' | 'devDependencies' | 'peerDependencies' }); } }); }); }); // Calculate depths (topological sort) const topologicalOrder = topologicalSort(nodes); // Detect circular dependencies const circularDependencies = detectCircularDependencies(nodes); return { nodes, edges, topologicalOrder, circularDependencies }; } /** Perform topological sort on dependency graph / function topologicalSort(nodes: Map<string, DependencyNode>): string[] { const visited = new Set<string>(); const temp = new Set<string>(); const result: string[] = []; function visit(nodeName: string): void { if (temp.has(nodeName)) return; // Circular dependency if (visited.has(nodeName)) return; temp.add(nodeName); const node = nodes.get(nodeName); if (node) { node.dependencies.forEach(depName => visit(depName)); node.depth = Math.max(node.depth, ...Array.from(node.dependencies).map(dep => (nodes.get(dep)?.depth || 0) + 1 )); } temp.delete(nodeName); visited.add(nodeName); result.push(nodeName); } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { visit(nodeName); } }); return result; } /** Detect circular dependencies in the graph / function detectCircularDependencies(nodes: Map<string, DependencyNode>): string[][] { const visited = new Set<string>(); const recursionStack = new Set<string>(); const cycles: string[][] = []; const currentPath: string[] = []; function dfs(nodeName: string): boolean { visited.add(nodeName); recursionStack.add(nodeName); currentPath.push(nodeName); const node = nodes.get(nodeName); if (node) { for (const depName of node.dependencies) { if (!visited.has(depName)) { if (dfs(depName)) return true; } else if (recursionStack.has(depName)) { // Found a cycle const cycleStart = currentPath.indexOf(depName); cycles.push(currentPath.slice(cycleStart).concat([depName])); return true; } } } currentPath.pop(); recursionStack.delete(nodeName); return false; } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { dfs(nodeName); } }); return cycles; } // Batch operations and utility functions /** Filter packages based on criteria / export function filterPackages( packages: WorkspacePackage[], filter: PackageFilter ): WorkspacePackage[] { return packages.filter(pkg => { if (filter.names && !filter.names.includes(pkg.name)) return false; if (filter.paths && !filter.paths.some(p => pkg.relativePath.includes(p))) return false; if (filter.hasScript && !pkg.scripts.has(filter.hasScript)) return false; if (filter.hasDependency) { const hasDep = pkg.dependencies.has(filter.hasDependency) || pkg.devDependencies.has(filter.hasDependency) || pkg.peerDependencies.has(filter.hasDependency); if (!hasDep) return false; } if (filter.isPrivate !== undefined && pkg.isPrivate !== filter.isPrivate) return false; if (filter.custom && !filter.custom(pkg)) return false; return true; }); } /** Run a script across multiple packages / export async function runScript( packages: WorkspacePackage[], scriptName: string, options: BatchOperationOptions = {} ): Promise<Map<string, { success: boolean; output?: string; error?: Error }>> { const { concurrency = 4, continueOnError = false, filter, scope, ignore = [], onProgress, onPackageComplete, onPackageError } = options; const results = new Map<string, { success: boolean; output?: string; error?: Error }>(); let filteredPackages = packages; // Apply filters if (filter) { filteredPackages = filterPackages(filteredPackages, filter); } if (scope) { filteredPackages = filteredPackages.filter(pkg => scope.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } if (ignore.length > 0) { filteredPackages = filteredPackages.filter(pkg => !ignore.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } // Filter packages that have the script const packagesWithScript = filteredPackages.filter(pkg => pkg.scripts.has(scriptName)); if (packagesWithScript.length === 0) { workspaceLogger.warn(`No packages found with script "${scriptName}"`); return results; } // Import execa here to avoid circular dependencies const { execa } = await import('../core/execution/execa.js'); let completed = 0; const total = packagesWithScript.length; const runPackageScript = async (pkg: WorkspacePackage): Promise<void> => { try { // Get the script command (we know it exists from the filter) pkg.scripts.get(scriptName)!; const result = await execa('npm', ['run', scriptName], { cwd: pkg.path, silent: true }); results.set(pkg.name, { success: true, output: result.stdout }); onPackageComplete?.(pkg, result); } catch (error) { const err = error instanceof Error ? error : new Error(String(error)); results.set(pkg.name, { success: false, error: err }); onPackageError?.(pkg, err); if (!continueOnError) { throw err; } } finally { completed++; onProgress?.(completed, total, pkg.name); } }; // Execute with concurrency limit const semaphore = Array(concurrency).fill(null); const packageQueue = [...packagesWithScript]; await Promise.all( semaphore.map(async () => { while (packageQueue.length > 0) { const pkg = packageQueue.shift(); if (pkg) { await runPackageScript(pkg); } } }) ); return results; } /** Install dependencies for packages

---

## isClean

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function isClean(cwd: string = process.cwd()): Promise<boolean>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available / export async function isGitAvailable(): Promise<boolean> { try { await execa('git', ['--version']); return true; } catch { return false; } } /** Get the git repository root directory / export async function getRepositoryRoot(cwd: string = process.cwd()): Promise<string> { try { const result = await execa('git', ['rev-parse', '--show-toplevel'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError('Not in a git repository', { code: 'NOT_GIT_REPOSITORY', suggestion: 'Run this command from within a git repository', context: { cwd }, cause: error instanceof Error ? error : undefined, }); } } /** Initialize a new git repository / export async function init( directory: string = process.cwd(), options: { bare?: boolean; defaultBranch?: string } = {} ): Promise<void> { const args = ['init']; if (options.bare) { args.push('--bare'); } if (options.defaultBranch) { args.push('--initial-branch', options.defaultBranch); } args.push(directory); try { await execa('git', args, { cwd: directory }); } catch (error) { throw new CLIError(`Failed to initialize git repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_INIT_FAILED', cause: error instanceof Error ? error : undefined, context: { directory, options }, }); } } /** Clone a git repository / export async function clone( url: string, directory: string, options: CloneOptions = {} ): Promise<void> { const args = ['clone']; if (options.branch) { args.push('--branch', options.branch); } if (options.depth) { args.push('--depth', options.depth.toString()); } if (options.recursive) { args.push('--recursive'); } if (options.progress) { args.push('--progress'); } args.push(url, directory); try { if (options.progress) { await execaStream('git', args); } else { await execa('git', args); } } catch (error) { throw new CLIError(`Failed to clone repository: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_CLONE_FAILED', cause: error instanceof Error ? error : undefined, context: { url, directory, options }, }); } } /** Get the current repository status / export async function getStatus(cwd: string = process.cwd()): Promise<GitStatus> { try { // Get current branch and tracking info const branchResult = await execa('git', ['branch', '--show-current'], { cwd }); const branch = branchResult.stdout.trim(); // Get ahead/behind counts let ahead = 0; let behind = 0; try { const trackingResult = await execa('git', ['rev-list', '--count', '--left-right', '@{upstream}...HEAD'], { cwd }); const [behindStr, aheadStr] = trackingResult.stdout.trim().split('\t'); behind = parseInt(behindStr) || 0; ahead = parseInt(aheadStr) || 0; } catch { // No upstream branch } // Get file status const statusResult = await execa('git', ['status', '--porcelain'], { cwd }); const lines = statusResult.stdout.trim().split('\n').filter(line => line); const staged: string[] = []; const unstaged: string[] = []; const untracked: string[] = []; for (const line of lines) { const statusCode = line.substring(0, 2); const fileName = line.substring(3); if (statusCode[0] !== ' ' && statusCode[0] !== '?') { staged.push(fileName); } if (statusCode[1] !== ' ' && statusCode[1] !== '?') { unstaged.push(fileName); } if (statusCode === '??') { untracked.push(fileName); } } return { branch, ahead, behind, staged, unstaged, untracked, clean: staged.length === 0 && unstaged.length === 0 && untracked.length === 0, }; } catch (error) { throw new CLIError(`Failed to get git status: ${error instanceof Error ? error.message : String(error)}`, { code: 'GIT_STATUS_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Add files to the staging area / export async function add( files: string | string[], cwd: string = process.cwd() ): Promise<void> { const fileList = Array.isArray(files) ? files : [files]; const args = ['add', ...fileList]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to add files`, { code: 'GIT_ADD_FAILED', cause: error instanceof Error ? error : undefined, context: { files, cwd }, }); } } /** Create a commit / export async function commit( options: CommitOptions, cwd: string = process.cwd() ): Promise<string> { const args = ['commit', '-m', options.message]; if (options.amend) { args.push('--amend'); } if (options.signOff) { args.push('--signoff'); } if (options.allowEmpty) { args.push('--allow-empty'); } try { const result = await gitExeca(args, { cwd }); // Extract commit hash from output const match = result.stdout.match(/\[.+ ([a-f0-9]+)\]/); return match ? match[1] : ''; } catch (error) { throw new CLIError(`Failed to create commit`, { code: 'GIT_COMMIT_FAILED', cause: error instanceof Error ? error : undefined, context: { options, cwd }, }); } } /** Get commit history / export async function getCommits( count: number = 10, cwd: string = process.cwd() ): Promise<GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await gitExeca(['log', `-${count}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message, }; }); } catch (error) { throw new CLIError(`Failed to get commits`, { code: 'GIT_LOG_FAILED', cause: error instanceof Error ? error : undefined, context: { count, cwd }, }); } } /** Get basic diff information / export async function getDiff( from?: string, to?: string, cwd: string = process.cwd() ): Promise<string> { const args = ['diff']; if (from) { args.push(from); if (to) { args.push(to); } } try { const result = await gitExeca(args, { cwd }); return result.stdout; } catch (error) { throw new CLIError(`Failed to get diff`, { code: 'GIT_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { from, to, cwd }, }); } } /** Get branches / export async function getBranches( cwd: string = process.cwd(), includeRemote: boolean = false ): Promise<string[]> { const args = ['branch']; if (includeRemote) { args.push('-a'); } try { const result = await gitExeca(args, { cwd }); return result.stdout .trim() .split('\n') .map(line => line.replace(/^\*?\s+/, '').trim()) .filter(line => line && !line.startsWith('->')); } catch (error) { throw new CLIError(`Failed to list branches`, { code: 'GIT_BRANCH_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, includeRemote }, }); } } /** Create a new branch / export async function createBranch( name: string, cwd: string = process.cwd(), checkout: boolean = false ): Promise<void> { const args = checkout ? ['checkout', '-b', name] : ['branch', name]; try { await gitExeca(args, { cwd }); } catch (error) { throw new CLIError(`Failed to create branch`, { code: 'GIT_BRANCH_CREATE_FAILED', cause: error instanceof Error ? error : undefined, context: { name, cwd, checkout }, }); } } /** Checkout a branch or commit / export async function checkout( ref: string, cwd: string = process.cwd() ): Promise<void> { try { await gitExeca(['checkout', ref], { cwd }); } catch (error) { throw new CLIError(`Failed to checkout`, { code: 'GIT_CHECKOUT_FAILED', cause: error instanceof Error ? error : undefined, context: { ref, cwd }, }); } } /** Get the current commit hash / export async function getCurrentCommit(cwd: string = process.cwd()): Promise<string> { try { const result = await gitExeca(['rev-parse', 'HEAD'], { cwd }); return result.stdout.trim(); } catch (error) { throw new CLIError(`Failed to get current commit`, { code: 'GIT_COMMIT_HASH_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd }, }); } } /** Check if the working directory is clean (no uncommitted changes)

---

## isGitAvailable

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function isGitAvailable(): Promise<boolean>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository / export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean> { try { await execa('git', ['rev-parse', '--git-dir'], { cwd }); return true; } catch { return false; } } /** Check if git is installed and available

---

## isGitRepository

**Type**: `function`  
**Source**: [`src/plugins/git.ts`](../../../src/plugins/git.ts)

```typescript
export async function isGitRepository(cwd: string = process.cwd()): Promise<boolean>
```

Git Plugin - Repository operations and version control utilities Provides essential git functionality for CLI tools including: - Repository status and validation - Basic operations (init, clone, add, commit) - Branch and remote management - Utility functions for version control workflows / import { execa, execaStream } from '../core/execution/execa.js'; import { CLIError } from '../core/foundation/errors/errors.js'; export interface GitStatus { branch: string; ahead: number; behind: number; staged: string[]; unstaged: string[]; untracked: string[]; clean: boolean; } export interface GitCommit { hash: string; shortHash: string; author: string; email: string; date: Date; message: string; } export interface CloneOptions { branch?: string; depth?: number; recursive?: boolean; progress?: boolean; } export interface CommitOptions { message: string; amend?: boolean; signOff?: boolean; allowEmpty?: boolean; } // Helper function to execute git commands with proper error handling async function gitExeca( args: string[], options: { cwd?: string; stream?: boolean } = {} ): Promise<{ stdout: string; stderr: string }> { try { if (options.stream) { await execaStream('git', args, { cwd: options.cwd }); return { stdout: '', stderr: '' }; } else { return await execa('git', args, { cwd: options.cwd }); } } catch (error) { throw new CLIError( `Git command failed: git ${args.join(' ')}`, { code: 'GIT_COMMAND_FAILED', cause: error instanceof Error ? error : undefined, context: { args, options } } ); } } /** Check if the current directory is a git repository

---

## isWorkspace

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean>
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace

---

## LernaConfiguration

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## loadWorkspace

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function loadWorkspace(cwd: string = process.cwd()): Promise<WorkspaceConfiguration>
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace / export async function discoverPackages( cwd: string = process.cwd(), workspaceType?: WorkspaceType ): Promise<WorkspacePackage[]> { const type = workspaceType || await detectWorkspaceType(cwd); const packages: WorkspacePackage[] = []; try { let packagePaths: string[] = []; switch (type) { case 'nx': packagePaths = await discoverNxPackages(cwd); break; case 'lerna': packagePaths = await discoverLernaPackages(cwd); break; case 'rush': packagePaths = await discoverRushPackages(cwd); break; case 'pnpm-workspace': case 'yarn-workspace': case 'npm-workspace': packagePaths = await discoverWorkspacesPackages(cwd); break; case 'turbo': // Turbo usually relies on other workspace configurations packagePaths = await discoverWorkspacesPackages(cwd); break; case 'multi-tool': // Try multiple discovery methods packagePaths = await discoverMultiToolPackages(cwd); break; case 'single-package': packagePaths = [cwd]; break; } // Process each discovered package for (const packagePath of packagePaths) { try { const pkg = await loadPackage(packagePath, cwd); if (pkg) { packages.push(pkg); } } catch (error) { workspaceLogger.warn(`Failed to load package at ${packagePath}: ${error}`); } } return packages; } catch (error) { throw new CLIError(`Failed to discover packages in workspace`, { code: 'WORKSPACE_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, workspaceType: type } }); } } /** Load a single package from a directory / async function loadPackage( packagePath: string, workspaceRoot: string ): Promise<WorkspacePackage | null> { const packageJsonPath = path.join(packagePath, 'package.json'); if (!await exists(packageJsonPath)) { return null; } try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (!packageJson.name) { workspaceLogger.warn(`Package at ${packagePath} has no name field`); return null; } const dependencies = new Map(Object.entries(packageJson.dependencies || {})); const devDependencies = new Map(Object.entries(packageJson.devDependencies || {})); const peerDependencies = new Map(Object.entries(packageJson.peerDependencies || {})); const scripts = new Map(Object.entries(packageJson.scripts || {})); return { name: packageJson.name, version: packageJson.version || '0.0.0', path: packagePath, relativePath: path.relative(workspaceRoot, packagePath), packageJson, dependencies, devDependencies, peerDependencies, scripts, isPrivate: packageJson.private || false, workspaceDependencies: [] // Will be populated later }; } catch (error) { throw new CLIError(`Failed to parse package.json at ${packagePath}`, { code: 'PACKAGE_JSON_PARSE_FAILED', cause: error instanceof Error ? error : undefined, context: { packagePath } }); } } // Package discovery methods for different workspace types async function discoverNxPackages(cwd: string): Promise<string[]> { const paths: string[] = []; try { // Try nx.json first const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { const nxConfig: NxConfiguration = JSON.parse(await readFile(nxJsonPath)); if (nxConfig.projects) { for (const [, projectConfig] of Object.entries(nxConfig.projects)) { if (typeof projectConfig === 'string') { paths.push(path.join(cwd, projectConfig)); } else if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, projectConfig.root as string)); } } } } // Try workspace.json as fallback const workspaceJsonPath = path.join(cwd, 'workspace.json'); if (paths.length === 0 && await exists(workspaceJsonPath)) { const workspaceConfig = JSON.parse(await readFile(workspaceJsonPath)); if (workspaceConfig.projects) { for (const [, projectConfig] of Object.entries(workspaceConfig.projects)) { if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, (projectConfig as any).root)); } } } } // If no explicit projects, scan common patterns if (paths.length === 0) { const patterns = ['apps/*', 'libs/*', 'packages/*', 'projects/*']; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } } return paths; } catch (error) { throw new CLIError('Failed to discover Nx packages', { code: 'NX_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverLernaPackages(cwd: string): Promise<string[]> { try { const lernaJsonPath = path.join(cwd, 'lerna.json'); const lernaConfig: LernaConfiguration = JSON.parse(await readFile(lernaJsonPath)); const patterns = lernaConfig.packages || ['packages/*']; const paths: string[] = []; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover Lerna packages', { code: 'LERNA_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverRushPackages(cwd: string): Promise<string[]> { try { const rushJsonPath = path.join(cwd, 'rush.json'); const rushConfig: RushConfiguration = JSON.parse(await readFile(rushJsonPath)); return rushConfig.projects.map(project => path.join(cwd, project.projectFolder) ); } catch (error) { throw new CLIError('Failed to discover Rush packages', { code: 'RUSH_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverWorkspacesPackages(cwd: string): Promise<string[]> { try { const packageJsonPath = path.join(cwd, 'package.json'); const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); let workspacePatterns: string[] = []; if (packageJson.workspaces) { if (Array.isArray(packageJson.workspaces)) { workspacePatterns = packageJson.workspaces; } else if (packageJson.workspaces.packages) { workspacePatterns = packageJson.workspaces.packages; } } // Check pnpm-workspace.yaml const pnpmWorkspacePath = path.join(cwd, 'pnpm-workspace.yaml'); if (workspacePatterns.length === 0 && await exists(pnpmWorkspacePath)) { try { // Simple YAML parsing for packages field const yamlContent = await readFile(pnpmWorkspacePath); const packagesMatch = yamlContent.match(/packages:\s*\n((?:\s*-\s*.+\n?)*)/); if (packagesMatch) { workspacePatterns = packagesMatch[1] .split('\n') .map(line => line.trim().replace(/^-\s*/, '').replace(/['"](.+)['"]/, '$1')) .filter(Boolean); } } catch (error) { workspaceLogger.warn(`Failed to parse pnpm-workspace.yaml: ${error}`); } } if (workspacePatterns.length === 0) { // Default patterns if none specified workspacePatterns = ['packages/*']; } const paths: string[] = []; for (const pattern of workspacePatterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover workspace packages', { code: 'WORKSPACES_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverMultiToolPackages(cwd: string): Promise<string[]> { const allPaths: Set<string> = new Set(); // Try all discovery methods and combine results const discoveryMethods = [ () => discoverNxPackages(cwd), () => discoverLernaPackages(cwd), () => discoverWorkspacesPackages(cwd), () => discoverRushPackages(cwd) ]; for (const method of discoveryMethods) { try { const paths = await method(); paths.forEach(p => allPaths.add(p)); } catch { // Ignore errors from individual discovery methods } } return Array.from(allPaths); } /** Load complete workspace configuration

---

## NxConfiguration

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## PackageFilter

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## PackageJson

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## PackageManager

**Type**: `type`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## parseVersion

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export function parseVersion(versionString: string): SemanticVersion
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string

---

## PLACEHOLDER_CONFIG_LOADER

**Type**: `constant`  
**Source**: [`src/plugins/placeholders.ts`](../../../src/plugins/placeholders.ts)

---

## PLACEHOLDER_GIT

**Type**: `constant`  
**Source**: [`src/plugins/placeholders.ts`](../../../src/plugins/placeholders.ts)

---

## PLACEHOLDER_TELEMETRY

**Type**: `constant`  
**Source**: [`src/plugins/placeholders.ts`](../../../src/plugins/placeholders.ts)

---

## PLACEHOLDER_UPDATER

**Type**: `constant`  
**Source**: [`src/plugins/placeholders.ts`](../../../src/plugins/placeholders.ts)

---

## PLACEHOLDER_WORKSPACE

**Type**: `constant`  
**Source**: [`src/plugins/placeholders.ts`](../../../src/plugins/placeholders.ts)

---

## runScript

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function runScript(
  packages: WorkspacePackage[],
  scriptName: string,
  options: BatchOperationOptions =
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace / export async function discoverPackages( cwd: string = process.cwd(), workspaceType?: WorkspaceType ): Promise<WorkspacePackage[]> { const type = workspaceType || await detectWorkspaceType(cwd); const packages: WorkspacePackage[] = []; try { let packagePaths: string[] = []; switch (type) { case 'nx': packagePaths = await discoverNxPackages(cwd); break; case 'lerna': packagePaths = await discoverLernaPackages(cwd); break; case 'rush': packagePaths = await discoverRushPackages(cwd); break; case 'pnpm-workspace': case 'yarn-workspace': case 'npm-workspace': packagePaths = await discoverWorkspacesPackages(cwd); break; case 'turbo': // Turbo usually relies on other workspace configurations packagePaths = await discoverWorkspacesPackages(cwd); break; case 'multi-tool': // Try multiple discovery methods packagePaths = await discoverMultiToolPackages(cwd); break; case 'single-package': packagePaths = [cwd]; break; } // Process each discovered package for (const packagePath of packagePaths) { try { const pkg = await loadPackage(packagePath, cwd); if (pkg) { packages.push(pkg); } } catch (error) { workspaceLogger.warn(`Failed to load package at ${packagePath}: ${error}`); } } return packages; } catch (error) { throw new CLIError(`Failed to discover packages in workspace`, { code: 'WORKSPACE_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, workspaceType: type } }); } } /** Load a single package from a directory / async function loadPackage( packagePath: string, workspaceRoot: string ): Promise<WorkspacePackage | null> { const packageJsonPath = path.join(packagePath, 'package.json'); if (!await exists(packageJsonPath)) { return null; } try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (!packageJson.name) { workspaceLogger.warn(`Package at ${packagePath} has no name field`); return null; } const dependencies = new Map(Object.entries(packageJson.dependencies || {})); const devDependencies = new Map(Object.entries(packageJson.devDependencies || {})); const peerDependencies = new Map(Object.entries(packageJson.peerDependencies || {})); const scripts = new Map(Object.entries(packageJson.scripts || {})); return { name: packageJson.name, version: packageJson.version || '0.0.0', path: packagePath, relativePath: path.relative(workspaceRoot, packagePath), packageJson, dependencies, devDependencies, peerDependencies, scripts, isPrivate: packageJson.private || false, workspaceDependencies: [] // Will be populated later }; } catch (error) { throw new CLIError(`Failed to parse package.json at ${packagePath}`, { code: 'PACKAGE_JSON_PARSE_FAILED', cause: error instanceof Error ? error : undefined, context: { packagePath } }); } } // Package discovery methods for different workspace types async function discoverNxPackages(cwd: string): Promise<string[]> { const paths: string[] = []; try { // Try nx.json first const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { const nxConfig: NxConfiguration = JSON.parse(await readFile(nxJsonPath)); if (nxConfig.projects) { for (const [, projectConfig] of Object.entries(nxConfig.projects)) { if (typeof projectConfig === 'string') { paths.push(path.join(cwd, projectConfig)); } else if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, projectConfig.root as string)); } } } } // Try workspace.json as fallback const workspaceJsonPath = path.join(cwd, 'workspace.json'); if (paths.length === 0 && await exists(workspaceJsonPath)) { const workspaceConfig = JSON.parse(await readFile(workspaceJsonPath)); if (workspaceConfig.projects) { for (const [, projectConfig] of Object.entries(workspaceConfig.projects)) { if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, (projectConfig as any).root)); } } } } // If no explicit projects, scan common patterns if (paths.length === 0) { const patterns = ['apps/*', 'libs/*', 'packages/*', 'projects/*']; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } } return paths; } catch (error) { throw new CLIError('Failed to discover Nx packages', { code: 'NX_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverLernaPackages(cwd: string): Promise<string[]> { try { const lernaJsonPath = path.join(cwd, 'lerna.json'); const lernaConfig: LernaConfiguration = JSON.parse(await readFile(lernaJsonPath)); const patterns = lernaConfig.packages || ['packages/*']; const paths: string[] = []; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover Lerna packages', { code: 'LERNA_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverRushPackages(cwd: string): Promise<string[]> { try { const rushJsonPath = path.join(cwd, 'rush.json'); const rushConfig: RushConfiguration = JSON.parse(await readFile(rushJsonPath)); return rushConfig.projects.map(project => path.join(cwd, project.projectFolder) ); } catch (error) { throw new CLIError('Failed to discover Rush packages', { code: 'RUSH_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverWorkspacesPackages(cwd: string): Promise<string[]> { try { const packageJsonPath = path.join(cwd, 'package.json'); const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); let workspacePatterns: string[] = []; if (packageJson.workspaces) { if (Array.isArray(packageJson.workspaces)) { workspacePatterns = packageJson.workspaces; } else if (packageJson.workspaces.packages) { workspacePatterns = packageJson.workspaces.packages; } } // Check pnpm-workspace.yaml const pnpmWorkspacePath = path.join(cwd, 'pnpm-workspace.yaml'); if (workspacePatterns.length === 0 && await exists(pnpmWorkspacePath)) { try { // Simple YAML parsing for packages field const yamlContent = await readFile(pnpmWorkspacePath); const packagesMatch = yamlContent.match(/packages:\s*\n((?:\s*-\s*.+\n?)*)/); if (packagesMatch) { workspacePatterns = packagesMatch[1] .split('\n') .map(line => line.trim().replace(/^-\s*/, '').replace(/['"](.+)['"]/, '$1')) .filter(Boolean); } } catch (error) { workspaceLogger.warn(`Failed to parse pnpm-workspace.yaml: ${error}`); } } if (workspacePatterns.length === 0) { // Default patterns if none specified workspacePatterns = ['packages/*']; } const paths: string[] = []; for (const pattern of workspacePatterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover workspace packages', { code: 'WORKSPACES_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverMultiToolPackages(cwd: string): Promise<string[]> { const allPaths: Set<string> = new Set(); // Try all discovery methods and combine results const discoveryMethods = [ () => discoverNxPackages(cwd), () => discoverLernaPackages(cwd), () => discoverWorkspacesPackages(cwd), () => discoverRushPackages(cwd) ]; for (const method of discoveryMethods) { try { const paths = await method(); paths.forEach(p => allPaths.add(p)); } catch { // Ignore errors from individual discovery methods } } return Array.from(allPaths); } /** Load complete workspace configuration / export async function loadWorkspace(cwd: string = process.cwd()): Promise<WorkspaceConfiguration> { try { const workspaceType = await detectWorkspaceType(cwd); const packageManager = await detectPackageManager(cwd); const packages = await discoverPackages(cwd, workspaceType); const tools = await loadWorkspaceTools(cwd); // Create package map for quick lookups const packageMap = new Map<string, WorkspacePackage>(); packages.forEach(pkg => packageMap.set(pkg.name, pkg)); // Build dependency graph const dependencyGraph = buildDependencyGraph(packages); // Load workspace-level scripts const scripts = await loadWorkspaceScripts(cwd); return { type: workspaceType, root: cwd, packages, packageMap, dependencyGraph, tools, packageManager, scripts }; } catch (error) { throw new CLIError(`Failed to load workspace configuration`, { code: 'WORKSPACE_LOAD_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } /** Load workspace tools configuration / async function loadWorkspaceTools(cwd: string): Promise<WorkspaceTools> { const tools: WorkspaceTools = { hasNx: false, hasLerna: false, hasRush: false, hasTurbo: false, hasWorkspaces: false, configurations: {} }; // Check for Nx const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { tools.hasNx = true; try { tools.configurations.nx = JSON.parse(await readFile(nxJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse nx.json: ${error}`); } } // Check for Lerna const lernaJsonPath = path.join(cwd, 'lerna.json'); if (await exists(lernaJsonPath)) { tools.hasLerna = true; try { tools.configurations.lerna = JSON.parse(await readFile(lernaJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse lerna.json: ${error}`); } } // Check for Rush const rushJsonPath = path.join(cwd, 'rush.json'); if (await exists(rushJsonPath)) { tools.hasRush = true; try { tools.configurations.rush = JSON.parse(await readFile(rushJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse rush.json: ${error}`); } } // Check for Turbo const turboJsonPath = path.join(cwd, 'turbo.json'); if (await exists(turboJsonPath)) { tools.hasTurbo = true; try { tools.configurations.turbo = JSON.parse(await readFile(turboJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse turbo.json: ${error}`); } } // Check for workspaces const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { tools.hasWorkspaces = true; if (Array.isArray(packageJson.workspaces)) { tools.configurations.workspaces = { packages: packageJson.workspaces }; } else if (packageJson.workspaces.packages) { tools.configurations.workspaces = packageJson.workspaces; } } } catch (error) { workspaceLogger.warn(`Failed to parse package.json: ${error}`); } } return tools; } /** Load workspace-level scripts / async function loadWorkspaceScripts(cwd: string): Promise<Map<string, string>> { const scripts = new Map<string, string>(); try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.scripts) { Object.entries(packageJson.scripts).forEach(([name, script]) => { scripts.set(name, script); }); } } } catch (error) { workspaceLogger.warn(`Failed to load workspace scripts: ${error}`); } return scripts; } /** Build dependency graph for workspace packages / function buildDependencyGraph(packages: WorkspacePackage[]): DependencyGraph { const nodes = new Map<string, DependencyNode>(); const edges: DependencyEdge[] = []; const packageNames = new Set(packages.map(pkg => pkg.name)); // Initialize nodes packages.forEach(pkg => { nodes.set(pkg.name, { name: pkg.name, package: pkg, dependencies: new Set(), dependents: new Set(), depth: 0 }); }); // Build edges and populate workspace dependencies packages.forEach(pkg => { const node = nodes.get(pkg.name)!; // Process dependencies ['dependencies', 'devDependencies', 'peerDependencies'].forEach(depType => { const deps = pkg[depType as keyof WorkspacePackage] as Map<string, string> | undefined; if (!deps) return; deps.forEach((_, depName) => { if (packageNames.has(depName)) { // This is a workspace dependency pkg.workspaceDependencies.push(depName); node.dependencies.add(depName); const targetNode = nodes.get(depName); if (targetNode) { targetNode.dependents.add(pkg.name); } edges.push({ from: pkg.name, to: depName, type: depType as 'dependencies' | 'devDependencies' | 'peerDependencies' }); } }); }); }); // Calculate depths (topological sort) const topologicalOrder = topologicalSort(nodes); // Detect circular dependencies const circularDependencies = detectCircularDependencies(nodes); return { nodes, edges, topologicalOrder, circularDependencies }; } /** Perform topological sort on dependency graph / function topologicalSort(nodes: Map<string, DependencyNode>): string[] { const visited = new Set<string>(); const temp = new Set<string>(); const result: string[] = []; function visit(nodeName: string): void { if (temp.has(nodeName)) return; // Circular dependency if (visited.has(nodeName)) return; temp.add(nodeName); const node = nodes.get(nodeName); if (node) { node.dependencies.forEach(depName => visit(depName)); node.depth = Math.max(node.depth, ...Array.from(node.dependencies).map(dep => (nodes.get(dep)?.depth || 0) + 1 )); } temp.delete(nodeName); visited.add(nodeName); result.push(nodeName); } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { visit(nodeName); } }); return result; } /** Detect circular dependencies in the graph / function detectCircularDependencies(nodes: Map<string, DependencyNode>): string[][] { const visited = new Set<string>(); const recursionStack = new Set<string>(); const cycles: string[][] = []; const currentPath: string[] = []; function dfs(nodeName: string): boolean { visited.add(nodeName); recursionStack.add(nodeName); currentPath.push(nodeName); const node = nodes.get(nodeName); if (node) { for (const depName of node.dependencies) { if (!visited.has(depName)) { if (dfs(depName)) return true; } else if (recursionStack.has(depName)) { // Found a cycle const cycleStart = currentPath.indexOf(depName); cycles.push(currentPath.slice(cycleStart).concat([depName])); return true; } } } currentPath.pop(); recursionStack.delete(nodeName); return false; } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { dfs(nodeName); } }); return cycles; } // Batch operations and utility functions /** Filter packages based on criteria / export function filterPackages( packages: WorkspacePackage[], filter: PackageFilter ): WorkspacePackage[] { return packages.filter(pkg => { if (filter.names && !filter.names.includes(pkg.name)) return false; if (filter.paths && !filter.paths.some(p => pkg.relativePath.includes(p))) return false; if (filter.hasScript && !pkg.scripts.has(filter.hasScript)) return false; if (filter.hasDependency) { const hasDep = pkg.dependencies.has(filter.hasDependency) || pkg.devDependencies.has(filter.hasDependency) || pkg.peerDependencies.has(filter.hasDependency); if (!hasDep) return false; } if (filter.isPrivate !== undefined && pkg.isPrivate !== filter.isPrivate) return false; if (filter.custom && !filter.custom(pkg)) return false; return true; }); } /** Run a script across multiple packages

---

## RushConfiguration

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## satisfiesRange

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export function satisfiesRange(version: SemanticVersion, range: string): boolean
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation)

---

## SemanticVersion

**Type**: `interface`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

---

## tagExists

**Type**: `function`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

```typescript
export async function tagExists(tag: string, cwd: string = process.cwd()): Promise<boolean>
```

Updater Plugin - Version comparison and patch application engine Provides semantic version management and project update capabilities: - Semantic version parsing and comparison - Git-based version diffing and change detection - Patch application and conflict resolution - Update planning and validation / import * as git from './git.js'; import { execa } from '../core/execution/execa.js'; import { ensureDir, copyFile, exists } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { logger } from '../core/ui/logger.js'; import path from 'node:path'; import fs from 'node:fs/promises'; // Semantic Version interfaces and types export interface SemanticVersion { major: number; minor: number; patch: number; prerelease?: string; build?: string; raw: string; } export interface VersionDiff { from: SemanticVersion; to: SemanticVersion; changeType: 'major' | 'minor' | 'patch' | 'prerelease' | 'none'; files: FileDiff[]; commits: git.GitCommit[]; breaking: boolean; } export interface FileDiff { path: string; status: 'added' | 'modified' | 'deleted' | 'renamed'; oldPath?: string; // For renamed files insertions: number; deletions: number; content?: { before?: string; after?: string; }; } export interface UpdatePlan { fromVersion: string; toVersion: string; diff: VersionDiff; conflicts: UpdateConflict[]; strategy: UpdateStrategy; backupRequired: boolean; } export interface UpdateConflict { file: string; type: 'content' | 'deletion' | 'permission' | 'dependency'; description: string; resolution?: 'skip' | 'overwrite' | 'merge' | 'manual'; } export interface UpdateStrategy { type: 'overwrite' | 'merge' | 'selective'; excludePaths: string[]; preserveFiles: string[]; customMergers: Record<string, (local: string, remote: string) => string>; } export interface UpdateOptions { strategy?: Partial<UpdateStrategy>; createBackup?: boolean; dryRun?: boolean; force?: boolean; interactive?: boolean; } // Semantic Version utilities const VERSION_REGEX = /^(\d+)\.(\d+)\.(\d+)(?:-([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?(?:\+([a-zA-Z0-9-]+(?:\.[a-zA-Z0-9-]+)*))?$/; /** Parse a semantic version string / export function parseVersion(versionString: string): SemanticVersion { // Handle 'v' prefix const cleaned = versionString.replace(/^v/, ''); const match = cleaned.match(VERSION_REGEX); if (!match) { throw new CLIError(`Invalid semantic version: ${versionString}`, { code: 'INVALID_SEMVER', suggestion: 'Use format: major.minor.patch[-prerelease][+build]' }); } const [, major, minor, patch, prerelease, build] = match; return { major: parseInt(major, 10), minor: parseInt(minor, 10), patch: parseInt(patch, 10), prerelease, build, raw: versionString }; } /** Compare two semantic versions Returns -1 if a < b, 0 if a === b, 1 if a > b / export function compareVersions(a: SemanticVersion, b: SemanticVersion): number { // Compare major.minor.patch if (a.major !== b.major) return a.major - b.major; if (a.minor !== b.minor) return a.minor - b.minor; if (a.patch !== b.patch) return a.patch - b.patch; // Handle prerelease precedence if (!a.prerelease && !b.prerelease) return 0; if (!a.prerelease && b.prerelease) return 1; if (a.prerelease && !b.prerelease) return -1; // Compare prerelease versions if (a.prerelease && b.prerelease) { const aParts = a.prerelease.split('.'); const bParts = b.prerelease.split('.'); const maxLength = Math.max(aParts.length, bParts.length); for (let i = 0; i < maxLength; i++) { const aPart = aParts[i] || ''; const bPart = bParts[i] || ''; if (aPart !== bPart) { // Numeric comparison if both are numbers const aNum = parseInt(aPart, 10); const bNum = parseInt(bPart, 10); if (!isNaN(aNum) && !isNaN(bNum)) { return aNum - bNum; } // Lexical comparison otherwise return aPart < bPart ? -1 : 1; } } } return 0; } /** Determine the type of version change / export function getChangeType(from: SemanticVersion, to: SemanticVersion): 'major' | 'minor' | 'patch' | 'prerelease' | 'none' { if (from.major !== to.major) return 'major'; if (from.minor !== to.minor) return 'minor'; if (from.patch !== to.patch) return 'patch'; if (from.prerelease !== to.prerelease) return 'prerelease'; return 'none'; } /** Check if a version satisfies a range (simple implementation) / export function satisfiesRange(version: SemanticVersion, range: string): boolean { // Basic range patterns: "^1.2.3", "~1.2.3", ">=1.2.3", "1.2.3" if (range.startsWith('^')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('~')) { const targetVersion = parseVersion(range.slice(1)); return version.major === targetVersion.major && version.minor === targetVersion.minor && compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) >= 0; } if (range.startsWith('>')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) > 0; } if (range.startsWith('<=')) { const targetVersion = parseVersion(range.slice(2)); return compareVersions(version, targetVersion) <= 0; } if (range.startsWith('<')) { const targetVersion = parseVersion(range.slice(1)); return compareVersions(version, targetVersion) < 0; } // Exact match const targetVersion = parseVersion(range); return compareVersions(version, targetVersion) === 0; } // Git-based version diffing /** Get detailed diff between two git tags/commits / export async function getVersionDiff( fromTag: string, toTag: string, cwd: string = process.cwd() ): Promise<VersionDiff> { const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); try { // Get commit history between versions const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); // Get file changes const files = await getFilesBetweenTags(fromTag, toTag, cwd); // Determine if this is a breaking change const breaking = await isBreakingChange(fromTag, toTag, cwd); return { from: fromVersion, to: toVersion, changeType: getChangeType(fromVersion, toVersion), files, commits, breaking }; } catch (error) { throw new CLIError(`Failed to get version diff from ${fromTag} to ${toTag}`, { code: 'VERSION_DIFF_FAILED', cause: error instanceof Error ? error : undefined, context: { fromTag, toTag, cwd } }); } } /** Get commits between two git tags / async function getCommitsBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<git.GitCommit[]> { try { const format = '--pretty=format:%H|%h|%an|%ae|%ai|%s'; const result = await execa('git', ['log', `${fromTag}..${toTag}`, format], { cwd }); return result.stdout .trim() .split('\n') .filter(line => line) .map(line => { const [hash, shortHash, author, email, date, message] = line.split('|'); return { hash, shortHash, author, email, date: new Date(date), message }; }); } catch (error) { throw new CLIError(`Failed to get commits between ${fromTag} and ${toTag}`, { code: 'GIT_COMMITS_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Get detailed file changes between two git tags / async function getFilesBetweenTags( fromTag: string, toTag: string, cwd: string ): Promise<FileDiff[]> { try { // Get file stats const statsResult = await execa('git', ['diff', '--numstat', `${fromTag}..${toTag}`], { cwd }); const stats = new Map<string, { insertions: number; deletions: number }>(); for (const line of statsResult.stdout.trim().split('\n').filter(Boolean)) { const [insertions, deletions, path] = line.split('\t'); stats.set(path, { insertions: insertions === '-' ? 0 : parseInt(insertions, 10), deletions: deletions === '-' ? 0 : parseInt(deletions, 10) }); } // Get file status (added, modified, deleted, renamed) const nameStatusResult = await execa('git', ['diff', '--name-status', `${fromTag}..${toTag}`], { cwd }); const files: FileDiff[] = []; for (const line of nameStatusResult.stdout.trim().split('\n').filter(Boolean)) { const parts = line.split('\t'); const status = parts[0]; const path = parts[1]; let fileStatus: FileDiff['status']; let oldPath: string | undefined; if (status === 'A') { fileStatus = 'added'; } else if (status === 'D') { fileStatus = 'deleted'; } else if (status === 'M') { fileStatus = 'modified'; } else if (status.startsWith('R')) { fileStatus = 'renamed'; oldPath = path; // For renames, the new path is in parts[2] const newPath = parts[2]; const fileStats = stats.get(newPath) || { insertions: 0, deletions: 0 }; files.push({ path: newPath, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); continue; } else { fileStatus = 'modified'; // Default for other statuses } const fileStats = stats.get(path) || { insertions: 0, deletions: 0 }; files.push({ path, status: fileStatus, oldPath, insertions: fileStats.insertions, deletions: fileStats.deletions }); } return files; } catch (error) { throw new CLIError(`Failed to get file changes between ${fromTag} and ${toTag}`, { code: 'GIT_FILES_FAILED', cause: error instanceof Error ? error : undefined }); } } /** Heuristic to determine if changes are breaking / async function isBreakingChange( fromTag: string, toTag: string, cwd: string ): Promise<boolean> { try { // Check commit messages for breaking change indicators const commits = await getCommitsBetweenTags(fromTag, toTag, cwd); const breakingKeywords = [ 'BREAKING CHANGE', 'breaking change', 'BREAKING:', '!:', 'breaking:', 'BC:', 'bc:' ]; const hasBreakingCommit = commits.some(commit => breakingKeywords.some(keyword => commit.message.toLowerCase().includes(keyword.toLowerCase()) ) ); if (hasBreakingCommit) return true; // Check for major version bump const fromVersion = parseVersion(fromTag); const toVersion = parseVersion(toTag); return fromVersion.major !== toVersion.major; } catch { // Default to false if we can't determine return false; } } // Update planning and application /** Create an update plan for applying changes / export async function createUpdatePlan( fromVersion: string, toVersion: string, targetDir: string, options: UpdateOptions = {} ): Promise<UpdatePlan> { try { const diff = await getVersionDiff(fromVersion, toVersion, targetDir); const conflicts = await detectConflicts(diff, targetDir); const strategy: UpdateStrategy = { type: options.strategy?.type || 'merge', excludePaths: options.strategy?.excludePaths || [ '.git', 'node_modules', '.env', '.env.local' ], preserveFiles: options.strategy?.preserveFiles || [ 'package.json', 'README.md', '.gitignore' ], customMergers: options.strategy?.customMergers || {} }; return { fromVersion, toVersion, diff, conflicts, strategy, backupRequired: options.createBackup !== false || conflicts.length > 0 }; } catch (error) { throw new CLIError(`Failed to create update plan`, { code: 'UPDATE_PLAN_FAILED', cause: error instanceof Error ? error : undefined, context: { fromVersion, toVersion, targetDir } }); } } /** Detect potential conflicts in the update / async function detectConflicts( diff: VersionDiff, targetDir: string ): Promise<UpdateConflict[]> { const conflicts: UpdateConflict[] = []; for (const file of diff.files) { const filePath = path.join(targetDir, file.path); try { // Check if file exists and has local changes if (await exists(filePath)) { if (file.status === 'deleted') { conflicts.push({ file: file.path, type: 'deletion', description: `File exists locally but is deleted in the update`, resolution: 'manual' }); } else if (file.status === 'modified') { // Could check git status here to see if file has local changes const hasLocalChanges = await checkLocalChanges(filePath, targetDir); if (hasLocalChanges) { conflicts.push({ file: file.path, type: 'content', description: `File has both local and remote changes`, resolution: 'merge' }); } } } // Check file permissions const stats = await fs.stat(filePath).catch(() => null); if (stats && !stats.isFile()) { conflicts.push({ file: file.path, type: 'permission', description: `Path exists but is not a regular file`, resolution: 'skip' }); } } catch { // File doesn't exist - no conflict } } return conflicts; } /** Check if a file has local changes (not committed) / async function checkLocalChanges(filePath: string, cwd: string): Promise<boolean> { try { const relativePath = path.relative(cwd, filePath); const result = await execa('git', ['status', '--porcelain', relativePath], { cwd }); return result.stdout.trim().length > 0; } catch { return false; } } /** Apply an update plan / export async function applyUpdate( plan: UpdatePlan, targetDir: string, options: UpdateOptions = {} ): Promise<void> { if (options.dryRun) { logger.info('Dry run mode - no changes will be applied'); await logUpdatePlan(plan); return; } try { // Create backup if required if (plan.backupRequired && options.createBackup !== false) { await createBackup(targetDir); } // Apply changes based on strategy switch (plan.strategy.type) { case 'overwrite': await applyOverwriteStrategy(plan, targetDir, options); break; case 'merge': await applyMergeStrategy(plan, targetDir, options); break; case 'selective': await applySelectiveStrategy(plan, targetDir, options); break; } logger.success(`Successfully updated from ${plan.fromVersion} to ${plan.toVersion}`); } catch (error) { throw new CLIError(`Failed to apply update`, { code: 'UPDATE_APPLICATION_FAILED', cause: error instanceof Error ? error : undefined, context: { plan, targetDir, options } }); } } /** Create a backup of the target directory / async function createBackup(targetDir: string): Promise<string> { const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); const backupDir = `${targetDir}.backup.${timestamp}`; logger.info(`Creating backup at ${backupDir}`); try { await execa('cp', ['-r', targetDir, backupDir]); return backupDir; } catch { // Fallback for systems without cp await copyDirectory(targetDir, backupDir); return backupDir; } } /** Recursive directory copy fallback / async function copyDirectory(src: string, dest: string): Promise<void> { await ensureDir(dest); const items = await fs.readdir(src); for (const item of items) { const srcPath = path.join(src, item); const destPath = path.join(dest, item); const stats = await fs.stat(srcPath); if (stats.isDirectory()) { await copyDirectory(srcPath, destPath); } else { await copyFile(srcPath, destPath); } } } /** Apply overwrite strategy (replace everything) / async function applyOverwriteStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying overwrite strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } else if (file.status === 'added' || file.status === 'modified') { // This would require the source content - placeholder for now logger.info(`Would update: ${file.path}`); } } } /** Apply merge strategy (intelligent merging) / async function applyMergeStrategy( plan: UpdatePlan, targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying merge strategy'); for (const file of plan.diff.files) { if (plan.strategy.excludePaths.some(exclude => file.path.startsWith(exclude))) { continue; } const targetPath = path.join(targetDir, file.path); // Handle conflicts based on their resolution strategy const conflict = plan.conflicts.find(c => c.file === file.path); if (conflict) { await handleConflict(conflict, targetPath, plan.strategy); } else { // No conflict - apply change directly if (file.status === 'added' || file.status === 'modified') { logger.info(`Would update: ${file.path}`); } else if (file.status === 'deleted') { if (await exists(targetPath)) { await fs.unlink(targetPath); logger.info(`Deleted: ${file.path}`); } } } } } /** Apply selective strategy (user chooses what to update) / async function applySelectiveStrategy( _plan: UpdatePlan, _targetDir: string, _options: UpdateOptions ): Promise<void> { logger.info('Applying selective strategy'); // Implementation would involve prompting user for each file change // This is a placeholder for the selective update logic logger.info('Selective strategy not yet fully implemented'); } /** Handle update conflicts / async function handleConflict( conflict: UpdateConflict, _targetPath: string, _strategy: UpdateStrategy ): Promise<void> { switch (conflict.resolution) { case 'skip': logger.warn(`Skipping conflicted file: ${conflict.file}`); break; case 'overwrite': logger.warn(`Overwriting conflicted file: ${conflict.file}`); // Implementation would overwrite the file break; case 'merge': logger.info(`Attempting to merge conflicted file: ${conflict.file}`); // Implementation would use git merge or custom merger break; case 'manual': logger.error(`Manual resolution required for: ${conflict.file}`); logger.info(`  ${conflict.description}`); break; } } /** Log the update plan details / async function logUpdatePlan(plan: UpdatePlan): Promise<void> { logger.info(`Update Plan: ${plan.fromVersion} â†’ ${plan.toVersion}`); logger.info(`Change Type: ${plan.diff.changeType}`); logger.info(`Breaking: ${plan.diff.breaking ? 'Yes' : 'No'}`); logger.info(`Strategy: ${plan.strategy.type}`); if (plan.diff.files.length > 0) { logger.info('\nFile Changes:'); for (const file of plan.diff.files) { const status = file.status.charAt(0).toUpperCase() + file.status.slice(1); logger.info(`  ${status}: ${file.path} (+${file.insertions}/-${file.deletions})`); } } if (plan.conflicts.length > 0) { logger.warn('\nConflicts:'); for (const conflict of plan.conflicts) { logger.warn(`  ${conflict.file}: ${conflict.description}`); } } if (plan.diff.commits.length > 0) { logger.info('\nCommits:'); for (const commit of plan.diff.commits.slice(0, 5)) { logger.info(`  ${commit.shortHash}: ${commit.message}`); } if (plan.diff.commits.length > 5) { logger.info(`  ... and ${plan.diff.commits.length - 5} more commits`); } } } // Utility functions for version management /** Get the latest tag in the repository / export async function getLatestTag(cwd: string = process.cwd()): Promise<string | null> { try { const result = await execa('git', ['describe', '--tags', '--abbrev=0'], { cwd, silent: true }); return result.stdout.trim() || null; } catch { return null; } } /** Get all tags in the repository, sorted by version / export async function getAllTags(cwd: string = process.cwd()): Promise<string[]> { try { const result = await execa('git', ['tag', '-l'], { cwd }); const tags = result.stdout.trim().split('\n').filter(Boolean); // Sort tags by semantic version return tags.sort((a, b) => { try { const versionA = parseVersion(a); const versionB = parseVersion(b); return compareVersions(versionA, versionB); } catch { // Fallback to string comparison for non-semver tags return a.localeCompare(b); } }); } catch { return []; } } /** Check if a tag exists in the repository

---

## TurboConfiguration

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## UpdateConflict

**Type**: `interface`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

---

## UpdateOptions

**Type**: `interface`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

---

## UpdatePlan

**Type**: `interface`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

---

## UpdateStrategy

**Type**: `interface`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

---

## validateWorkspace

**Type**: `function`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

```typescript
export async function validateWorkspace(
  workspace: WorkspaceConfiguration
): Promise<
```

Workspace Plugin - Monorepo detection and management utilities Provides comprehensive monorepo support for CLI tools including: - Multi-tool monorepo detection (Nx, Lerna, Rush, Turborepo, pnpm, yarn, npm workspaces) - Package discovery and workspace mapping - Dependency analysis and graph building - Batch operations across packages - Change detection and affected package identification / import { readFile, exists, readDir } from '../core/execution/fs.js'; import { CLIError } from '../core/foundation/errors/errors.js'; import { createLogger } from '../core/ui/logger.js'; import path from 'node:path'; const workspaceLogger = createLogger({ prefix: 'workspace' }); // Simple glob pattern matching for workspace patterns async function simpleGlob(pattern: string, options: { cwd: string; onlyDirectories?: boolean }): Promise<string[]> { const { cwd, onlyDirectories = false } = options; // Handle simple wildcard patterns like "packages/*" or "apps/*" if (pattern.endsWith('/*')) { const baseDir = pattern.slice(0, -2); const fullPath = path.join(cwd, baseDir); if (!exists(fullPath)) { return []; } try { const entries = await readDir(fullPath); const results = []; for (const entry of entries) { if (onlyDirectories && !entry.isDirectory) continue; results.push(path.join(baseDir, entry.name)); } return results; } catch { return []; } } // For exact patterns, just check if they exist const fullPath = path.join(cwd, pattern); if (exists(fullPath)) { return [pattern]; } return []; } // Core workspace interfaces export interface WorkspacePackage { name: string; version: string; path: string; relativePath: string; packageJson: PackageJson; dependencies: Map<string, string>; devDependencies: Map<string, string>; peerDependencies: Map<string, string>; scripts: Map<string, string>; isPrivate: boolean; workspaceDependencies: string[]; } export interface PackageJson { name?: string; version?: string; description?: string; main?: string; module?: string; types?: string; scripts?: Record<string, string>; dependencies?: Record<string, string>; devDependencies?: Record<string, string>; peerDependencies?: Record<string, string>; optionalDependencies?: Record<string, string>; private?: boolean; workspaces?: string[] | { packages: string[]; nohoist?: string[] }; nx?: Record<string, any>; turbo?: Record<string, any>; [key: string]: any; } export interface WorkspaceConfiguration { type: WorkspaceType; root: string; packages: WorkspacePackage[]; packageMap: Map<string, WorkspacePackage>; dependencyGraph: DependencyGraph; tools: WorkspaceTools; packageManager: PackageManager; scripts: Map<string, string>; } export interface WorkspaceTools { hasNx: boolean; hasLerna: boolean; hasRush: boolean; hasTurbo: boolean; hasWorkspaces: boolean; configurations: { nx?: NxConfiguration; lerna?: LernaConfiguration; rush?: RushConfiguration; turbo?: TurboConfiguration; workspaces?: WorkspacesConfiguration; }; } export interface DependencyGraph { nodes: Map<string, DependencyNode>; edges: DependencyEdge[]; topologicalOrder: string[]; circularDependencies: string[][]; } export interface DependencyNode { name: string; package: WorkspacePackage; dependencies: Set<string>; dependents: Set<string>; depth: number; } export interface DependencyEdge { from: string; to: string; type: 'dependencies' | 'devDependencies' | 'peerDependencies'; } // Workspace tool configurations export interface NxConfiguration { version: string; projects: Record<string, any>; targetDefaults?: Record<string, any>; namedInputs?: Record<string, any>; generators?: Record<string, any>; tasksRunnerOptions?: Record<string, any>; } export interface LernaConfiguration { version: string; packages: string[]; npmClient?: string; useWorkspaces?: boolean; command?: Record<string, any>; } export interface RushConfiguration { rushVersion: string; projects: Array<{ packageName: string; projectFolder: string; reviewCategory?: string; }>; nodeSupportedVersionRange?: string; } export interface TurboConfiguration { schema?: string; globalDependencies?: string[]; pipeline: Record<string, any>; globalEnv?: string[]; } export interface WorkspacesConfiguration { packages: string[]; nohoist?: string[]; } // Enums and types export type WorkspaceType = | 'nx' | 'lerna' | 'rush' | 'turbo' | 'pnpm-workspace' | 'yarn-workspace' | 'npm-workspace' | 'multi-tool' | 'single-package'; export type PackageManager = 'npm' | 'yarn' | 'pnpm' | 'bun' | 'rush' | 'auto'; export interface BatchOperationOptions { concurrency?: number; continueOnError?: boolean; filter?: PackageFilter; scope?: string[]; ignore?: string[]; since?: string; onProgress?: (current: number, total: number, packageName: string) => void; onPackageComplete?: (pkg: WorkspacePackage, result: any) => void; onPackageError?: (pkg: WorkspacePackage, error: Error) => void; } export interface PackageFilter { names?: string[]; paths?: string[]; hasScript?: string; hasDependency?: string; isPrivate?: boolean; custom?: (pkg: WorkspacePackage) => boolean; } export interface ChangeDetectionOptions { since?: string; base?: string; head?: string; includeUncommitted?: boolean; includeDependents?: boolean; maxDepth?: number; } // Package manager detection const LOCKFILE_PATTERNS: Record<PackageManager, string[]> = { npm: ['package-lock.json'], yarn: ['yarn.lock'], pnpm: ['pnpm-lock.yaml'], bun: ['bun.lockb'], rush: ['rush.json', 'common/config/rush/rush.json'], auto: [] }; /** Detect if the current directory contains a monorepo workspace / export async function isWorkspace(cwd: string = process.cwd()): Promise<boolean> { try { await detectWorkspaceType(cwd); return true; } catch { return false; } } /** Detect the type of workspace/monorepo setup / export async function detectWorkspaceType(cwd: string = process.cwd()): Promise<WorkspaceType> { const detectors = [ { type: 'nx' as const, files: ['nx.json', 'workspace.json'] }, { type: 'rush' as const, files: ['rush.json'] }, { type: 'lerna' as const, files: ['lerna.json'] }, { type: 'turbo' as const, files: ['turbo.json'] }, { type: 'pnpm-workspace' as const, files: ['pnpm-workspace.yaml'] } ]; const detectedTools: WorkspaceType[] = []; // Check for specific workspace configuration files for (const detector of detectors) { for (const file of detector.files) { if (await exists(path.join(cwd, file))) { detectedTools.push(detector.type); break; } } } // Check for npm/yarn workspaces in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { // Determine if it's npm or yarn based on lockfiles if (await exists(path.join(cwd, 'yarn.lock'))) { detectedTools.push('yarn-workspace'); } else { detectedTools.push('npm-workspace'); } } } } catch { // Ignore package.json parse errors } // Return the most specific type (prioritize explicit tool configs over generic workspaces) if (detectedTools.length === 0) { return 'single-package'; } else if (detectedTools.length === 1) { return detectedTools[0]; } else { // When multiple tools are detected, prioritize specific tools over generic workspaces const priorityOrder: WorkspaceType[] = ['nx', 'rush', 'lerna', 'turbo', 'pnpm-workspace', 'yarn-workspace', 'npm-workspace']; for (const tool of priorityOrder) { if (detectedTools.includes(tool)) { return tool; } } return 'multi-tool'; } } /** Detect the package manager being used / export async function detectPackageManager(cwd: string = process.cwd()): Promise<PackageManager> { // Check for specific lockfiles for (const [manager, patterns] of Object.entries(LOCKFILE_PATTERNS)) { if (manager === 'auto') continue; for (const pattern of patterns) { if (await exists(path.join(cwd, pattern))) { return manager as PackageManager; } } } // Check for packageManager field in package.json try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.packageManager) { const manager = packageJson.packageManager.split('@')[0]; if (['npm', 'yarn', 'pnpm', 'bun'].includes(manager)) { return manager as PackageManager; } } } } catch { // Ignore parse errors } return 'npm'; // Default fallback } /** Discover all packages in the workspace / export async function discoverPackages( cwd: string = process.cwd(), workspaceType?: WorkspaceType ): Promise<WorkspacePackage[]> { const type = workspaceType || await detectWorkspaceType(cwd); const packages: WorkspacePackage[] = []; try { let packagePaths: string[] = []; switch (type) { case 'nx': packagePaths = await discoverNxPackages(cwd); break; case 'lerna': packagePaths = await discoverLernaPackages(cwd); break; case 'rush': packagePaths = await discoverRushPackages(cwd); break; case 'pnpm-workspace': case 'yarn-workspace': case 'npm-workspace': packagePaths = await discoverWorkspacesPackages(cwd); break; case 'turbo': // Turbo usually relies on other workspace configurations packagePaths = await discoverWorkspacesPackages(cwd); break; case 'multi-tool': // Try multiple discovery methods packagePaths = await discoverMultiToolPackages(cwd); break; case 'single-package': packagePaths = [cwd]; break; } // Process each discovered package for (const packagePath of packagePaths) { try { const pkg = await loadPackage(packagePath, cwd); if (pkg) { packages.push(pkg); } } catch (error) { workspaceLogger.warn(`Failed to load package at ${packagePath}: ${error}`); } } return packages; } catch (error) { throw new CLIError(`Failed to discover packages in workspace`, { code: 'WORKSPACE_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd, workspaceType: type } }); } } /** Load a single package from a directory / async function loadPackage( packagePath: string, workspaceRoot: string ): Promise<WorkspacePackage | null> { const packageJsonPath = path.join(packagePath, 'package.json'); if (!await exists(packageJsonPath)) { return null; } try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (!packageJson.name) { workspaceLogger.warn(`Package at ${packagePath} has no name field`); return null; } const dependencies = new Map(Object.entries(packageJson.dependencies || {})); const devDependencies = new Map(Object.entries(packageJson.devDependencies || {})); const peerDependencies = new Map(Object.entries(packageJson.peerDependencies || {})); const scripts = new Map(Object.entries(packageJson.scripts || {})); return { name: packageJson.name, version: packageJson.version || '0.0.0', path: packagePath, relativePath: path.relative(workspaceRoot, packagePath), packageJson, dependencies, devDependencies, peerDependencies, scripts, isPrivate: packageJson.private || false, workspaceDependencies: [] // Will be populated later }; } catch (error) { throw new CLIError(`Failed to parse package.json at ${packagePath}`, { code: 'PACKAGE_JSON_PARSE_FAILED', cause: error instanceof Error ? error : undefined, context: { packagePath } }); } } // Package discovery methods for different workspace types async function discoverNxPackages(cwd: string): Promise<string[]> { const paths: string[] = []; try { // Try nx.json first const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { const nxConfig: NxConfiguration = JSON.parse(await readFile(nxJsonPath)); if (nxConfig.projects) { for (const [, projectConfig] of Object.entries(nxConfig.projects)) { if (typeof projectConfig === 'string') { paths.push(path.join(cwd, projectConfig)); } else if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, projectConfig.root as string)); } } } } // Try workspace.json as fallback const workspaceJsonPath = path.join(cwd, 'workspace.json'); if (paths.length === 0 && await exists(workspaceJsonPath)) { const workspaceConfig = JSON.parse(await readFile(workspaceJsonPath)); if (workspaceConfig.projects) { for (const [, projectConfig] of Object.entries(workspaceConfig.projects)) { if (projectConfig && typeof projectConfig === 'object' && 'root' in projectConfig) { paths.push(path.join(cwd, (projectConfig as any).root)); } } } } // If no explicit projects, scan common patterns if (paths.length === 0) { const patterns = ['apps/*', 'libs/*', 'packages/*', 'projects/*']; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } } return paths; } catch (error) { throw new CLIError('Failed to discover Nx packages', { code: 'NX_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverLernaPackages(cwd: string): Promise<string[]> { try { const lernaJsonPath = path.join(cwd, 'lerna.json'); const lernaConfig: LernaConfiguration = JSON.parse(await readFile(lernaJsonPath)); const patterns = lernaConfig.packages || ['packages/*']; const paths: string[] = []; for (const pattern of patterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover Lerna packages', { code: 'LERNA_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverRushPackages(cwd: string): Promise<string[]> { try { const rushJsonPath = path.join(cwd, 'rush.json'); const rushConfig: RushConfiguration = JSON.parse(await readFile(rushJsonPath)); return rushConfig.projects.map(project => path.join(cwd, project.projectFolder) ); } catch (error) { throw new CLIError('Failed to discover Rush packages', { code: 'RUSH_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverWorkspacesPackages(cwd: string): Promise<string[]> { try { const packageJsonPath = path.join(cwd, 'package.json'); const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); let workspacePatterns: string[] = []; if (packageJson.workspaces) { if (Array.isArray(packageJson.workspaces)) { workspacePatterns = packageJson.workspaces; } else if (packageJson.workspaces.packages) { workspacePatterns = packageJson.workspaces.packages; } } // Check pnpm-workspace.yaml const pnpmWorkspacePath = path.join(cwd, 'pnpm-workspace.yaml'); if (workspacePatterns.length === 0 && await exists(pnpmWorkspacePath)) { try { // Simple YAML parsing for packages field const yamlContent = await readFile(pnpmWorkspacePath); const packagesMatch = yamlContent.match(/packages:\s*\n((?:\s*-\s*.+\n?)*)/); if (packagesMatch) { workspacePatterns = packagesMatch[1] .split('\n') .map(line => line.trim().replace(/^-\s*/, '').replace(/['"](.+)['"]/, '$1')) .filter(Boolean); } } catch (error) { workspaceLogger.warn(`Failed to parse pnpm-workspace.yaml: ${error}`); } } if (workspacePatterns.length === 0) { // Default patterns if none specified workspacePatterns = ['packages/*']; } const paths: string[] = []; for (const pattern of workspacePatterns) { const matches = await simpleGlob(pattern, { cwd, onlyDirectories: true }); paths.push(...matches.map((match: string) => path.join(cwd, match))); } return paths; } catch (error) { throw new CLIError('Failed to discover workspace packages', { code: 'WORKSPACES_DISCOVERY_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } async function discoverMultiToolPackages(cwd: string): Promise<string[]> { const allPaths: Set<string> = new Set(); // Try all discovery methods and combine results const discoveryMethods = [ () => discoverNxPackages(cwd), () => discoverLernaPackages(cwd), () => discoverWorkspacesPackages(cwd), () => discoverRushPackages(cwd) ]; for (const method of discoveryMethods) { try { const paths = await method(); paths.forEach(p => allPaths.add(p)); } catch { // Ignore errors from individual discovery methods } } return Array.from(allPaths); } /** Load complete workspace configuration / export async function loadWorkspace(cwd: string = process.cwd()): Promise<WorkspaceConfiguration> { try { const workspaceType = await detectWorkspaceType(cwd); const packageManager = await detectPackageManager(cwd); const packages = await discoverPackages(cwd, workspaceType); const tools = await loadWorkspaceTools(cwd); // Create package map for quick lookups const packageMap = new Map<string, WorkspacePackage>(); packages.forEach(pkg => packageMap.set(pkg.name, pkg)); // Build dependency graph const dependencyGraph = buildDependencyGraph(packages); // Load workspace-level scripts const scripts = await loadWorkspaceScripts(cwd); return { type: workspaceType, root: cwd, packages, packageMap, dependencyGraph, tools, packageManager, scripts }; } catch (error) { throw new CLIError(`Failed to load workspace configuration`, { code: 'WORKSPACE_LOAD_FAILED', cause: error instanceof Error ? error : undefined, context: { cwd } }); } } /** Load workspace tools configuration / async function loadWorkspaceTools(cwd: string): Promise<WorkspaceTools> { const tools: WorkspaceTools = { hasNx: false, hasLerna: false, hasRush: false, hasTurbo: false, hasWorkspaces: false, configurations: {} }; // Check for Nx const nxJsonPath = path.join(cwd, 'nx.json'); if (await exists(nxJsonPath)) { tools.hasNx = true; try { tools.configurations.nx = JSON.parse(await readFile(nxJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse nx.json: ${error}`); } } // Check for Lerna const lernaJsonPath = path.join(cwd, 'lerna.json'); if (await exists(lernaJsonPath)) { tools.hasLerna = true; try { tools.configurations.lerna = JSON.parse(await readFile(lernaJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse lerna.json: ${error}`); } } // Check for Rush const rushJsonPath = path.join(cwd, 'rush.json'); if (await exists(rushJsonPath)) { tools.hasRush = true; try { tools.configurations.rush = JSON.parse(await readFile(rushJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse rush.json: ${error}`); } } // Check for Turbo const turboJsonPath = path.join(cwd, 'turbo.json'); if (await exists(turboJsonPath)) { tools.hasTurbo = true; try { tools.configurations.turbo = JSON.parse(await readFile(turboJsonPath)); } catch (error) { workspaceLogger.warn(`Failed to parse turbo.json: ${error}`); } } // Check for workspaces const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { try { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.workspaces) { tools.hasWorkspaces = true; if (Array.isArray(packageJson.workspaces)) { tools.configurations.workspaces = { packages: packageJson.workspaces }; } else if (packageJson.workspaces.packages) { tools.configurations.workspaces = packageJson.workspaces; } } } catch (error) { workspaceLogger.warn(`Failed to parse package.json: ${error}`); } } return tools; } /** Load workspace-level scripts / async function loadWorkspaceScripts(cwd: string): Promise<Map<string, string>> { const scripts = new Map<string, string>(); try { const packageJsonPath = path.join(cwd, 'package.json'); if (await exists(packageJsonPath)) { const packageJson: PackageJson = JSON.parse(await readFile(packageJsonPath)); if (packageJson.scripts) { Object.entries(packageJson.scripts).forEach(([name, script]) => { scripts.set(name, script); }); } } } catch (error) { workspaceLogger.warn(`Failed to load workspace scripts: ${error}`); } return scripts; } /** Build dependency graph for workspace packages / function buildDependencyGraph(packages: WorkspacePackage[]): DependencyGraph { const nodes = new Map<string, DependencyNode>(); const edges: DependencyEdge[] = []; const packageNames = new Set(packages.map(pkg => pkg.name)); // Initialize nodes packages.forEach(pkg => { nodes.set(pkg.name, { name: pkg.name, package: pkg, dependencies: new Set(), dependents: new Set(), depth: 0 }); }); // Build edges and populate workspace dependencies packages.forEach(pkg => { const node = nodes.get(pkg.name)!; // Process dependencies ['dependencies', 'devDependencies', 'peerDependencies'].forEach(depType => { const deps = pkg[depType as keyof WorkspacePackage] as Map<string, string> | undefined; if (!deps) return; deps.forEach((_, depName) => { if (packageNames.has(depName)) { // This is a workspace dependency pkg.workspaceDependencies.push(depName); node.dependencies.add(depName); const targetNode = nodes.get(depName); if (targetNode) { targetNode.dependents.add(pkg.name); } edges.push({ from: pkg.name, to: depName, type: depType as 'dependencies' | 'devDependencies' | 'peerDependencies' }); } }); }); }); // Calculate depths (topological sort) const topologicalOrder = topologicalSort(nodes); // Detect circular dependencies const circularDependencies = detectCircularDependencies(nodes); return { nodes, edges, topologicalOrder, circularDependencies }; } /** Perform topological sort on dependency graph / function topologicalSort(nodes: Map<string, DependencyNode>): string[] { const visited = new Set<string>(); const temp = new Set<string>(); const result: string[] = []; function visit(nodeName: string): void { if (temp.has(nodeName)) return; // Circular dependency if (visited.has(nodeName)) return; temp.add(nodeName); const node = nodes.get(nodeName); if (node) { node.dependencies.forEach(depName => visit(depName)); node.depth = Math.max(node.depth, ...Array.from(node.dependencies).map(dep => (nodes.get(dep)?.depth || 0) + 1 )); } temp.delete(nodeName); visited.add(nodeName); result.push(nodeName); } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { visit(nodeName); } }); return result; } /** Detect circular dependencies in the graph / function detectCircularDependencies(nodes: Map<string, DependencyNode>): string[][] { const visited = new Set<string>(); const recursionStack = new Set<string>(); const cycles: string[][] = []; const currentPath: string[] = []; function dfs(nodeName: string): boolean { visited.add(nodeName); recursionStack.add(nodeName); currentPath.push(nodeName); const node = nodes.get(nodeName); if (node) { for (const depName of node.dependencies) { if (!visited.has(depName)) { if (dfs(depName)) return true; } else if (recursionStack.has(depName)) { // Found a cycle const cycleStart = currentPath.indexOf(depName); cycles.push(currentPath.slice(cycleStart).concat([depName])); return true; } } } currentPath.pop(); recursionStack.delete(nodeName); return false; } nodes.forEach((_, nodeName) => { if (!visited.has(nodeName)) { dfs(nodeName); } }); return cycles; } // Batch operations and utility functions /** Filter packages based on criteria / export function filterPackages( packages: WorkspacePackage[], filter: PackageFilter ): WorkspacePackage[] { return packages.filter(pkg => { if (filter.names && !filter.names.includes(pkg.name)) return false; if (filter.paths && !filter.paths.some(p => pkg.relativePath.includes(p))) return false; if (filter.hasScript && !pkg.scripts.has(filter.hasScript)) return false; if (filter.hasDependency) { const hasDep = pkg.dependencies.has(filter.hasDependency) || pkg.devDependencies.has(filter.hasDependency) || pkg.peerDependencies.has(filter.hasDependency); if (!hasDep) return false; } if (filter.isPrivate !== undefined && pkg.isPrivate !== filter.isPrivate) return false; if (filter.custom && !filter.custom(pkg)) return false; return true; }); } /** Run a script across multiple packages / export async function runScript( packages: WorkspacePackage[], scriptName: string, options: BatchOperationOptions = {} ): Promise<Map<string, { success: boolean; output?: string; error?: Error }>> { const { concurrency = 4, continueOnError = false, filter, scope, ignore = [], onProgress, onPackageComplete, onPackageError } = options; const results = new Map<string, { success: boolean; output?: string; error?: Error }>(); let filteredPackages = packages; // Apply filters if (filter) { filteredPackages = filterPackages(filteredPackages, filter); } if (scope) { filteredPackages = filteredPackages.filter(pkg => scope.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } if (ignore.length > 0) { filteredPackages = filteredPackages.filter(pkg => !ignore.some(pattern => pkg.name.includes(pattern) || pkg.relativePath.includes(pattern)) ); } // Filter packages that have the script const packagesWithScript = filteredPackages.filter(pkg => pkg.scripts.has(scriptName)); if (packagesWithScript.length === 0) { workspaceLogger.warn(`No packages found with script "${scriptName}"`); return results; } // Import execa here to avoid circular dependencies const { execa } = await import('../core/execution/execa.js'); let completed = 0; const total = packagesWithScript.length; const runPackageScript = async (pkg: WorkspacePackage): Promise<void> => { try { // Get the script command (we know it exists from the filter) pkg.scripts.get(scriptName)!; const result = await execa('npm', ['run', scriptName], { cwd: pkg.path, silent: true }); results.set(pkg.name, { success: true, output: result.stdout }); onPackageComplete?.(pkg, result); } catch (error) { const err = error instanceof Error ? error : new Error(String(error)); results.set(pkg.name, { success: false, error: err }); onPackageError?.(pkg, err); if (!continueOnError) { throw err; } } finally { completed++; onProgress?.(completed, total, pkg.name); } }; // Execute with concurrency limit const semaphore = Array(concurrency).fill(null); const packageQueue = [...packagesWithScript]; await Promise.all( semaphore.map(async () => { while (packageQueue.length > 0) { const pkg = packageQueue.shift(); if (pkg) { await runPackageScript(pkg); } } }) ); return results; } /** Install dependencies for packages / export async function installDependencies( packages: WorkspacePackage[], packageManager: PackageManager = 'npm', options: BatchOperationOptions = {} ): Promise<Map<string, { success: boolean; output?: string; error?: Error }>> { const { execa } = await import('../core/execution/execa.js'); const results = new Map<string, { success: boolean; output?: string; error?: Error }>(); let filteredPackages = packages; if (options.filter) { filteredPackages = filterPackages(filteredPackages, options.filter); } const commands: Record<PackageManager, string[]> = { npm: ['npm', 'install'], yarn: ['yarn', 'install'], pnpm: ['pnpm', 'install'], bun: ['bun', 'install'], rush: ['rush', 'install'], auto: ['npm', 'install'] // fallback }; const [cmd, ...args] = commands[packageManager]; let completed = 0; const total = filteredPackages.length; for (const pkg of filteredPackages) { try { const result = await execa(cmd, args, { cwd: pkg.path, silent: true }); results.set(pkg.name, { success: true, output: result.stdout }); options.onPackageComplete?.(pkg, result); } catch (error) { const err = error instanceof Error ? error : new Error(String(error)); results.set(pkg.name, { success: false, error: err }); options.onPackageError?.(pkg, err); if (!options.continueOnError) { throw err; } } finally { completed++; options.onProgress?.(completed, total, pkg.name); } } return results; } /** Get packages affected by changes since a specific commit/branch / export async function getAffectedPackages( workspace: WorkspaceConfiguration, options: ChangeDetectionOptions = {} ): Promise<WorkspacePackage[]> { const { since = 'HEAD~1', includeUncommitted = true, includeDependents = true, maxDepth = Infinity } = options; const { execa } = await import('../core/execution/execa.js'); const affectedPackages = new Set<string>(); try { // Get list of changed files const changedFiles = new Set<string>(); // Get committed changes try { const gitDiffResult = await execa('git', ['diff', '--name-only', since], { cwd: workspace.root, silent: true }); gitDiffResult.stdout.trim().split('\n').filter(Boolean).forEach(file => changedFiles.add(file) ); } catch (error) { workspaceLogger.warn(`Failed to get git diff: ${error}`); } // Get uncommitted changes if requested if (includeUncommitted) { try { const statusResult = await execa('git', ['status', '--porcelain'], { cwd: workspace.root, silent: true }); statusResult.stdout.trim().split('\n').filter(Boolean).forEach(line => { const file = line.substring(3); // Remove status prefix changedFiles.add(file); }); } catch (error) { workspaceLogger.warn(`Failed to get git status: ${error}`); } } // Find packages containing changed files for (const file of changedFiles) { for (const pkg of workspace.packages) { const relativePath = pkg.relativePath || path.relative(workspace.root, pkg.path); if (file.startsWith(relativePath + '/') || file === relativePath) { affectedPackages.add(pkg.name); break; } } } // Include dependents if requested if (includeDependents && affectedPackages.size > 0) { const dependentsToAdd = new Set<string>(); let currentDepth = 0; let currentLevel = new Set(affectedPackages); while (currentLevel.size > 0 && currentDepth < maxDepth) { const nextLevel = new Set<string>(); for (const pkgName of currentLevel) { const node = workspace.dependencyGraph.nodes.get(pkgName); if (node) { node.dependents.forEach(dependent => { if (!affectedPackages.has(dependent) && !dependentsToAdd.has(dependent)) { dependentsToAdd.add(dependent); nextLevel.add(dependent); } }); } } dependentsToAdd.forEach(dep => affectedPackages.add(dep)); currentLevel = nextLevel; currentDepth++; } } } catch (error) { throw new CLIError('Failed to detect affected packages', { code: 'AFFECTED_DETECTION_FAILED', cause: error instanceof Error ? error : undefined, context: { options } }); } return workspace.packages.filter(pkg => affectedPackages.has(pkg.name)); } /** Validate workspace configuration and packages

---

## VersionDiff

**Type**: `interface`  
**Source**: [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)

---

## WorkspaceConfiguration

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## WorkspacePackage

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## WorkspacesConfiguration

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## WorkspaceTools

**Type**: `interface`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

---

## WorkspaceType

**Type**: `type`  
**Source**: [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)

## ðŸ“ Source Files

- [`src/plugins/git.ts`](../../../src/plugins/git.ts)
- [`src/plugins/updater.ts`](../../../src/plugins/updater.ts)
- [`src/plugins/workspace.ts`](../../../src/plugins/workspace.ts)
- [`src/plugins/placeholders.ts`](../../../src/plugins/placeholders.ts)

---

*Generated on 2025-10-29T21:38:06.354Z*
